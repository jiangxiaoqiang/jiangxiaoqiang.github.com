<?xml version="1.0" encoding="utf-8"?>
<search>
  
    
    <entry>
      <title><![CDATA[迁移解析服务]]></title>
      <url>%2F2016%2F11%2F16%2Fmigration-parse-service%2F</url>
      <content type="text"><![CDATA[迁移解析服务是将服务在不同主机上部署。 启动服务在解析服务器上，使用如下命令启动Tomcat: 1./catalina.sh start 配置映射主机使用如下命令打开hosts文件： 1vim /etc/hosts 添加主机映射。 12192.168.24.195 hostname1192.168.24.226 hostname2 验证迁移部署完毕后一定要验证，因为在解析服务器上日志打印OK并不代表数据成功写入Kafka集群中，所以验证最后验证迁移是否成功，在Kafka服务器中，切换到Kafka的目录： 1cd /usr/hdp/2.4.3.0-227/kafka/bin 使用如下命令查看迁移是否成功： 1./kafka-console-consumer.sh --zookeeper localhost:2181 --topic 0720688 其中，0720688是需要消费的主题。启动解析服务后，将解析服务Tomcat日志中写入的主题拷贝进命令行中启动消费者，如果能够成功消费到数据，代表迁移成功。否则，迁移失败。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Redmine安装]]></title>
      <url>%2F2016%2F11%2F15%2Fredmine-install%2F</url>
      <content type="text"><![CDATA[Redmine简介Redmine 是一个网页界面的项目管理与缺陷跟踪管理系统的自由及开放源代码软件工具。它集成了项目管理所需的各项功能：日历、燃尽图和甘特图 以协助可视化表现项目与时间限制，问题跟踪和版本控制。此外，Redmine也可以同时处理多个项目。Redmine 是以 Ruby on Rails 撰写的架构，它横跨多个平台与数据库，它的设计很明显是受一些类似功能软件包的Trac所影响。此外，它也是Bitnami 应用库的一部分。 安装的环境是CentOS 7.2，查看CentOS版本可以使用命令： 1cat /etc/redhat-release 安装前查看Redmine版本的对应关系。 安装依赖包(Install pre-dependencies)使用如下命令安装依赖包。 1yum -y install zlib-devel curl-devel openssl-devel httpd-devel apr-devel apr-util-devel mysql-devel 安装Ruby(Install Ruby)12cd ~/Downloads # YOUR FOLDER OF CHOICEftp ftp.ruby-lang.org 如果ftp未安装，输入如下命令安装ftp。 1yum install -y ftp 从FTP上获取Ruby安装文件： 12345ftp&gt; Anonymous # USERLOGINftp&gt; 'none', just hit Enter # NO PASSWORDftp&gt; cd /pub/rubyftp&gt; get get ruby-1.8.7-p358.tar.gz # XXX is currently 358, as of 03/2012ftp&gt; bye 也可以使用wget下载安装文件，此处采用此种方式，使用wget命令下载能够看到文件下载的进度，FTP方式等了许久没有响应，遂放弃，采用wget下载： 1wget ftp://ftp.ruby-lang.org/pub/ruby/ruby-1.8.7-p358.tar.gz 解压安装文件： 1tar zxvf ruby-1.8.7-p358.tar.gz 安装： 1234cd ruby-1.8.7.p358./configuremakemake install 编译Ruby源码需要GCC(GNU C Compiler)，如果编译时提示没有安装GCC，输入如下命令安装： 1yum install gcc gcc-c++ kernel-devel 安装Ruby(Install Ruby (Option 2))1yum install ruby 检查安装是否成功： 1ruby -v 安装RubyGems 1.4.212345wget http://production.cf.rubygems.org/rubygems/rubygems-1.4.2.tgztar zxvf rubygems-1.4.2.tgzcd rubygems-1.4.2ruby setup.rbgem -v 安装Ruby on Rails1gem install rails -v=4.2 安装Redmine下载安装包： 1wget http://www.redmine.org/releases/redmine-3.3.1.tar.gz 解压缩： 1tar zxvf redmine-3.3.1.tar.gz 数据库配置(Link Redmine to the Database)12345678910#登录数据库mysql -u root -p#重置密码alter user root@localhost identified by '$zwkj123456ZWKJ';#创建数据库create database redmine character set utf8;#创建用户create user 'redmine'@'localhost' identified by '$zwkj123456ZWKJ';#添加权限grant all privileges on redmine.* to 'redmine'@'localhost'; Configure database.yml123cd /var/www/redmine/configcp database.yml.example database.ymlnano database.yml Rails配置(Rails Settings)1gem install bundler --verbose 启动Redmine参考资料： Redmine on CentOS installation HOWTO。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Redis使用]]></title>
      <url>%2F2016%2F11%2F15%2Fredis-using%2F</url>
      <content type="text"><![CDATA[过期时间生存时间可以通过使用 DEL 命令来删除整个 key 来移除，或者被 SET 和 GETSET 命令覆写(overwrite)。 123456789101112131415161718192021/** * 设置数据（永久有效） * * @param key //key * @param value //值 * @param db //数据库序号 */public static void set(String key, String value, Integer db) &#123; Jedis jredis = null; try &#123; JedisPool poolItem = pools.get(db); jredis = poolItem.getResource(); jredis.set(key, value); &#125; catch (Exception e) &#123; log.error("set value encount an error", e); &#125; finally &#123; if (jredis != null) &#123; jredis.close(); &#125; &#125;&#125; 取出包含指定规则的Key从Redis中取出包含指定规则的Key的集合。 123456789101112131415161718192021222324/** * 取出包含指定key的集合 */public void pushCacheStatusInfo() &#123; JedisPool jedisPool = RedisHelper.getRedisPool(0); Jedis jredis = null; try &#123; jredis = jedisPool.getResource(); //找到包含指定Key的集合 Set keys = jredis.keys("*websocketsession"); Iterator iteratorKeys = keys.iterator(); while (iteratorKeys.hasNext()) &#123; String redisKey = iteratorKeys.next().toString(); String session = jredis.get(redisKey); //do something &#125; &#125; catch (Exception ex) &#123; log.error("推送信息出错", ex); &#125; finally &#123; if (jredis != null) &#123; jredis.close(); &#125; &#125;&#125; 常用指令登录Redis： 1./redis-cli -h 192.168.24.252 -p 6379 查看客户端数量： 1192.168.24.252:6379&gt; info clients]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[电影《恋恋风尘》(Dust in the Wind)]]></title>
      <url>%2F2016%2F11%2F13%2Fdust-in-the-wind%2F</url>
      <content type="text"><![CDATA[评价一部作品，它的真实性在心里占有相当的重量。而上映于1987年《恋恋风尘》(Dust in the Wind)所讲述的故事给自己的感觉是真实的，对观众来说它是仅仅一件小事。但对当时亲身经历的主人公来说，这些都是刻骨铭心的回忆，相信许多人也会有相似的感受，那就是：初恋告吹。 第一次看《恋恋风尘》(Dust in the Wind)，还是在大二、大三的学生时期。当时只觉得非常新奇，电影原来可以拍的这样安静和特别。往后参加工作，反复观看，每一次观看感受都是如此相似。久远的记忆仿佛就在昨天，具有贫苦农村生活经验和当兵经历的人士观看效果更佳。整部电影没有夸张的剧情和场景，都是一个个简单的回忆按时间顺序依次展现。 电影里有2个场景给我的印象最深： 一次是在台北时，阿远得了气管炎，阿云专程过来看他，当阿云过来时，恒春仔已经睡下了，说明已是很晚了，看到躺在床上无力的阿远，阿云遂打了热水，用热水浸湿的帕子搭在阿远的额头上，没有对白。第二天很早时阿云去上班。注意电影并没有强调阿云整晚是如何休息的，但是从屋内摆设观众应该能够想到她整夜打盹的场景。当清晨阿远送她出门时，电影的镜头慢慢拉到阿云离去的背影。这个离去的场景，我想阿远一生都不会忘记。 一次是在部队时，士兵们聚在一起打台球，一群人突然在讨论7号(一个女孩子)，说是和男朋友闹翻了，才出来做(应该是皮肉生意)。谈起阿远时，说他都不出去玩一玩，跟大家显得格格不入，遂嘲讽他“坚心为君，独守我青春”，说着一起大笑起来。镜头切到阿远呕吐的镜头，我想，他是由于太过于思念阿云的缘故。不是自己，怎么能理解一个人在心中的位置，旁人是没法理解的。 当忙碌了一天的工作后，或者闲暇时刻，回到家打开电视看看这么一部简单轻松的电影，也不失为一种放松方式。 PS:优酷下面的群众的评论能发现很多细节。 恋恋风尘优酷播放地址 恋恋风豆瓣介绍页面 《恋恋风尘》影评]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Intellij-Idea远程调试]]></title>
      <url>%2F2016%2F11%2F12%2Fintellij-idea-remote-debbuging%2F</url>
      <content type="text"><![CDATA[因为我们用的是Tomcat，所以在IDEA中点击右上角那个“Edit Configurations”按钮，然后在弹出的界面中点击左上角的加号，选择tomcat server-&gt;remote。 服务器配置要让远程服务器运行的代码支持远程调试，则启动的时候必须加上特定的JVM参数，这些参数是： 1-Xdebug -Xrunjdwp:transport=dt_socket,suspend=n,server=y,address=$&#123;debug_port&#125; 其中的${debug_port}是用户自定义的，为debug端口，本例以53996端口为例。在Windows下到tomcat目录下的catalina.bat文件中，添加如下内容，设置catalina环境变量： 1set CATALINA_OPTS="-agentlib:jdwp=transport=dt_socket,address=53996,suspend=n,server=y" 如果是Linux，在catalina.sh文件中中，设置catalina环境变量： 1export CATALINA_OPTS="-agentlib:jdwp=transport=dt_socket,address=53996,suspend=n,server=y" 运行如下命令启动Tomcat： 12345#Windows下启动Tomcatcatalina.bat start#Linux下启动Tomcatcatalina.sh start 使用如下命令查看是否配置成功： 12345#Windows下用此命令查看netstat -ano#Linux下用此命令查看lsof -i:53996 查看是否有53996的端口处于监听状态。如下图所示： Intellij Idea配置Intellij Idea远程调试配置如下：]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Websocket数据查看]]></title>
      <url>%2F2016%2F11%2F12%2Fwebsocket-check%2F</url>
      <content type="text"><![CDATA[FireFox中查看WebSocket使用FireFox查看WebSocket内容需要安装一个WebSocket-Monitor插件。安装完毕后在FireFox的Web控制台(Ctrl + Shift + K)中。 Google Chrome中查看WebSocketGoogle Chrome自带查看模块，如下图所示。F12进入开发者页面，选择NetWork选项卡，选择WS(WebSocket)选项卡。 Fiddler中查看WebSocket在请求时选择任意WebSocket Session，即可出现WebSocket流量数据画面，不过是乱码，未找到合适的解决乱码的方案。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[grep使用]]></title>
      <url>%2F2016%2F11%2F12%2Fgrep%2F</url>
      <content type="text"><![CDATA[grep (global search regular expression(RE) and print out the line,全面搜索正则表达式并把行打印出来)是一种强大的文本搜索工具，它能使用正则表达式搜索文本，并把匹配的行打印出来。 Unix的grep家族包括grep、egrep和fgrep。egrep和fgrep的命令只跟grep有很小不同。egrep是grep的扩展，支持更多的re元字符， fgrep就是fixed grep或fast grep，它们把所有的字母都看作单词，也就是说，正则表达式中的元字符表示回其自身的字面意义，不再特殊。linux使用GNU版本的grep。它功能更强，可以通过-G、-E、-F命令行选项来使用egrep和fgrep的功能。 多个匹配模式1tail -f catalina.out | grep -e "苏E22222" -e "服务器" 使用此命令可以过滤catalina.out文件中包含苏E22222且包含服务器的内容。使用grep匹配“与”或者“或”模式grep命令加-e参数，这一扩展允许使用扩展模式匹配。例如，要抽取城市代码为2 1 9或2 1 6，方法如下： 1grep –E '219|216' 还可以为匹配的内容增加高亮的颜色。 1tail -f catalina.out |grep --color=auto -E 'topic|0194592|0720724|512|0146636|S000099' 全局配置自动显示颜色： 123vim ~/.bashrcalias grep='grep --color'source ~/.bashrc 选出不包含512且不包含topic的行。 1tail -f catalina.out |grep -v -E '512|topic']]></content>
    </entry>

    
    <entry>
      <title><![CDATA[地理位置纠偏]]></title>
      <url>%2F2016%2F11%2F08%2Flocation-rectifying%2F</url>
      <content type="text"><![CDATA[偏移的起因：天朝测绘局以国家安全为理由，用法律的形式对所有在天朝发行的地图类产品加了强制性规范，要求所有地图类产品都必须使用国家测绘局的一种加偏移的算法，对地图的真实坐标进行加偏移处理，之后才可能通过审批准许上市。因此，天朝的所有官方及商用地图的坐标都是偏移的，这种偏移属于非线性的，偏移量在300至500米不等，偏移方向也不定。这种加过偏移的地图坐标就是所谓“火星坐标”。GPS接收机本身接收卫星的信号，计算出本机所在位置的经纬度，在没有做特别处理的时候，这个经纬度是正确的。但是如果GPS支持加载地图的话，这个GPS中的地图就得受上述第一条法规的约束了，所以正式在天朝销售的行货GPS设备中的地图必须也得加偏移，处理成火星坐标。地理位置纠偏代码(处理成火星坐标)： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465/** Created by jiangxiaoqiang on 2016/11/7.* 适用于Google,高德体系的地图*/public class GpsDataTranslate &#123; /** * 圆周率 */ private static double PI = Math.PI; /** * 地球的半径(单位:米) */ private static double EARTH_RADIUS = 6378245.0; /** * ee: 椭球的偏心率(eccentricity of ellipsoid) */ private static double ECCENTRICITY_OF_ELLIPSOID = 0.0066934216229659433; private static boolean IsOutOfChina(double latitude, double longitude) &#123; return longitude &lt; 72.004 || longitude &gt; 137.8347 || (latitude &lt; 0.8293 || latitude &gt; 55.8271); &#125; private static double TransformLat(double x, double y) &#123; double num = -100.0 + 2.0 * x + 3.0 * y + 0.2 * y * y + 0.1 * x * y + 0.2 * Math.sqrt(Math.abs(x)); num += (20.0 * Math.sin(6.0 * x * PI) + 20.0 * Math.sin(2.0 * x * PI)) * 2.0 / 3.0; num += (20.0 * Math.sin(y * PI) + 40.0 * Math.sin(y / 3.0 * PI)) * 2.0 / 3.0; return num + (160.0 * Math.sin(y / 12.0 * PI) + 320.0 * Math.sin(y * PI / 30.0)) * 2.0 / 3.0; &#125; private static double TransformLon(double x, double y) &#123; double num = 300.0 + x + 2.0 * y + 0.1 * x * x + 0.1 * x * y + 0.1 * Math.sqrt(Math.abs(x)); num += (20.0 * Math.sin(6.0 * x * PI) + 20.0 * Math.sin(2.0 * x * PI)) * 2.0 / 3.0; num += (20.0 * Math.sin(x * PI) + 40.0 * Math.sin(x / 3.0 * PI)) * 2.0 / 3.0; return num + (150.0 * Math.sin(x / 12.0 * PI) + 300.0 * Math.sin(x / 30.0 * PI)) * 2.0 / 3.0; &#125; /** * 地理位置纠偏 * * @param wgLat * @param wgLon */ public static double[] transform(double wgLat, double wgLon) &#123; double[] latlng = new double[2]; if (IsOutOfChina(wgLat, wgLon)) &#123; latlng[0] = wgLat; latlng[1] = wgLon; return latlng; &#125; double dLat = TransformLat(wgLon - 105.0, wgLat - 35.0); double dLon = TransformLon(wgLon - 105.0, wgLat - 35.0); double radLat = wgLat / 180.0 * PI; double magic = Math.sin(radLat); magic = 1 - ECCENTRICITY_OF_ELLIPSOID * magic * magic; double sqrtMagic = Math.sqrt(magic); dLat = (dLat * 180.0) / ((EARTH_RADIUS * (1 - ECCENTRICITY_OF_ELLIPSOID)) / (magic * sqrtMagic) * PI); dLon = (dLon * 180.0) / (EARTH_RADIUS / sqrtMagic * Math.cos(radLat) * PI); latlng[0] = (wgLat + dLat); latlng[1] = (wgLon + dLon); return latlng; &#125;&#125; 一对纠偏的数据组示例： 1234567原始数据：29.54163(纬度)106.508188(经度)纠偏后数据：29.538885930651567(纬度)106.5120118854562(经度)]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Spring MVC-DispatcherServlet处理请求过程]]></title>
      <url>%2F2016%2F11%2F04%2Fspringmvc-dispatcherservlet%2F</url>
      <content type="text"><![CDATA[Spring MVC基于模型-视图-控制器(Model-View-Controller,MVC)模式，它能够帮助我们建立灵活和松耦合的Web程序.Spring MVC中用户请求如下图所示： 请求发出(HTTP Resquest)一个请求携带信息进入Spring MVC程序时，第一站是Spring的DispatcherServlet，它是接收所有用户请求的前端控制器Servlet。DispatcherServlet的任务是将请求转发给Spring MVC控制器(Controller)，控制器是用于处理用户请求的Spring Bean。 处理器映射(Handler Mapping)一般程序中会有不止一个控制器，那么DispatcherServlet需要知道将请求发送给哪个控制器，所以DispatcherServlet将会查询处理器映射(handler mapping)来确定请求的下一站，处理器映射会根据用户请求的URL来决定是哪个控制器。 控制器(Controller)DispatcherServlet选择了控制器之后，就会将请求发送给该控制器并等待控制器处理用户请求。控制器在完成了逻辑处理后，通常会返回处理结果并将这些结果在浏览器上显示，这些信息在Spring MVC中成为模型(Model)。 模型以及逻辑视图名称(Model)控制器仅仅返回模型信息往往是不够的，需要对模型信息进行格式化，生成用户友好的方式如html进行显示。所以模型信息将会被发送给一个视图(View，例如jsp视图。事实上，控制器同时产生了模型以及视图名称，将这些信息发送回DispatcherServlet。 视图解析器(View Parser)DispatcherServlet收到控制器的视图名称并不直接表示某个特定的JSP，这个视图名称仅仅是个逻辑值，DispatcherServlet为了找到真正的视图，会使用视图解析器(view resolver)将视图名称匹配成一个具体的视图。 视图(View)目前为止，DispatcherServlet知道了具体由哪个视图来显示模型信息，那么它就会将模型信息交付给视图，请求的任务到这里就完成了。 响应(HTTP Response)视图渲染模型信息并输出，该输出最后会传递给用户端，展示给用户查看。从以上步骤可以看到，Spring MVC要处理很多过程，但是大部分过程是Spring框架内部处理的，事实上，我们可以十分方便利用Spring MVC框架的编写功能强大的Web应用程序，下一章我们将搭建一个基础的Spring MVC实例程序。 原始地址： Spring MVC入门-DispatcherServlet处理请求过程]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Spring框架搭建]]></title>
      <url>%2F2016%2F11%2F04%2Fspring%2F</url>
      <content type="text"><![CDATA[Spring的不足： 配置太多 常见问题Could not open ServletContext resource [/WEB-INF/applicationContext.xml]ContextLoaderListener has its own context which is shared by all servlets and filters. By default it will search /WEB-INF/applicationContext.xml。 1234&lt;context-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;/WEB-INF/somewhere-else/root-context.xml&lt;/param-value&gt;&lt;/context-param&gt; Missing artifact org.aspectj:aspectjweaver:jar:1.8.0.M1According to a reported issue at springsource, aspectjweaver is “basically identical to AspectJ 1.7” except that it has early support for Java 8.As I don’t need Java 8 support, I basically added a compile dependency to the latest release version of aspectweaver: 12345&lt;dependency&gt; &lt;groupId&gt;org.aspectj&lt;/groupId&gt; &lt;artifactId&gt;aspectjweaver&lt;/artifactId&gt; &lt;version&gt;1.7.4&lt;/version&gt;&lt;/dependency&gt; This ensures that the 1.7.4 is used instead of the milestone release, and is an acceptable workaround for me, for the time being. Exception java.lang.ClassNotFoundException: org.apache.commons.dbcp.BasicDataSource在POM.xml中引入jar包。 12345&lt;dependency&gt; &lt;groupId&gt;commons-dbcp&lt;/groupId&gt; &lt;artifactId&gt;commons-dbcp&lt;/artifactId&gt; &lt;version&gt;1.2.2&lt;/version&gt;&lt;/dependency&gt; java.lang.NoClassDefFoundError: org/apache/ibatis/session/SqlSessionFactory引入jar包。 12345&lt;dependency&gt; &lt;groupId&gt;org.apache.ibatis&lt;/groupId&gt; &lt;artifactId&gt;ibatis-core&lt;/artifactId&gt; &lt;version&gt;3.0&lt;/version&gt;&lt;/dependency&gt;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Windows下用Nexus搭建Maven私服]]></title>
      <url>%2F2016%2F11%2F04%2Fmaven-private-service%2F</url>
      <content type="text"><![CDATA[Nexus简介使用Maven的中央仓库存在如下问题： Maven自己的中央库访问速度非常慢，外加GFW，基本没法用。 有些jar包由于版权原因，maven中央仓库没有，比如oracle JDBC驱动。另外也会有一些项目中用到的比较老的开源jar包， 中央仓库也没有。这种情况我们需要把jar包手动上传到私服。 公司自己开发的jar包并不开源，不能上传到maven中央仓库，只能部署到私服上面。 Nexus 是Maven仓库管理器，如果你使用Maven，你可以从Maven中央仓库下载所需要的构件（artifact），但这通常不是一个好的做法，你应该在本地架设一个Maven仓库服务器，在代理远程仓库的同时维护本地仓库，以节省带宽和时间，Nexus就可以满足这样的需要。此外，他还提供了强大的仓库管理功能，构件搜索功能，它基于REST，友好的UI是一个extjs的REST客户端，它占用较少的内存，基于简单文件系统而非数据库。这些优点使其日趋成为最流行的Maven仓库管理器。下载Nexus（nexus-3.0.1-01-win64.exe），安装完毕后访问本地Maven私服主页。 配置单个项目安装完毕后需要登录，默认的用户名密码是：admin/admin123。登录之后才会显示设置图标，才能添加repositories。将本地Maven私服路径配置到项目的pom.xml中即可。如下代码片段所示。 1234567891011121314151617181920212223242526&lt;repositories&gt; &lt;repository&gt; &lt;id&gt;nexus&lt;/id&gt; &lt;name&gt;my-nexus-repository&lt;/name&gt; &lt;url&gt;http://192.168.1.102:8081/repository/maven-public/&lt;/url&gt; &lt;releases&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/releases&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt;&lt;/repositories&gt;&lt;pluginRepositories&gt; &lt;pluginRepository&gt; &lt;id&gt;nexus&lt;/id&gt; &lt;name&gt;my-nexus-repository&lt;/name&gt; &lt;url&gt;http://192.168.1.102:8081/repository/maven-public/&lt;/url&gt; &lt;releases&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/releases&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/pluginRepository&gt;&lt;/pluginRepositories&gt; 如果在本地私服没有的jar包，会自动从中心服务器下载。至此，最简单的Maven私服搭建完毕。 配置全局应用在Maven的settings.xml中配置profile元素，这样就能让本机所有的Maven项目都使用自己的Maven私服。 1234567891011121314151617181920212223242526&lt;mirrors&gt; &lt;mirror&gt; &lt;id&gt;central&lt;/id&gt; &lt;mirrorOf&gt;*&lt;/mirrorOf&gt; &lt;name&gt;Human Readable Name for this Mirror.&lt;/name&gt; &lt;url&gt;http://localhost:8081/nexus/content/groups/public/&lt;/url&gt; &lt;/mirror&gt; &lt;/mirrors&gt; &lt;profiles&gt; &lt;profile&gt; &lt;id&gt;nexus&lt;/id&gt; &lt;repositories&gt; &lt;repository&gt; &lt;id&gt;nexus&lt;/id&gt; &lt;name&gt;Nexus&lt;/name&gt; &lt;url&gt;http://localhost:8081/nexus/content/groups/public/&lt;/url&gt; &lt;releases&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/releases&gt; &lt;snapshots&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt; &lt;/repositories&gt; &lt;/profile&gt;&lt;/profiles&gt;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Lombok精简Java代码]]></title>
      <url>%2F2016%2F11%2F04%2Flombok%2F</url>
      <content type="text"><![CDATA[lombok提供了简单的注解的形式来帮助我们简化消除一些必须有但显得很臃肿的java代码,特别是相对于POJO(Plain Ordinary Java Object)。安装Lombok Plugin和引入Jar包之后方可使用。 常用的 lombok 注解： @Data：注解在类上；提供类所有属性的 getting 和 setting 方法，此外还提供了equals、canEqual、hashCode、toString 方法 @Setter：注解在属性上；为属性提供 setting 方法 @Getter：注解在属性上；为属性提供 getting 方法 @Log4j：注解在类上；为类提供一个 属性名为log 的 log4j 日志对象 @NoArgsConstructor：注解在类上；为类提供一个无参的构造方法 @AllArgsConstructor：注解在类上；为类提供一个全参的构造方法 如果不使用lombok注解，代码是这样： 1234567891011121314151617181920public class Person &#123; private String id; private Logger log = Logger.getLogger(Person.class); public Person() &#123; &#125; public Person(String id) &#123; this.id = id; &#125; public String getId() &#123; return id; &#125; public void setId(String id) &#123; this.id = id; &#125;&#125; 使用lombok注解，代码是这样： 1234567@Data@Log4j@NoArgsConstructor@AllArgsConstructorpublic class Person &#123; private String id;&#125; 一旦POJO字段较多时精简的代码就很明显了，而且使用Lombok的代码更加干净、易读，添加@Data注解之后，按Ctrl + O(Outline)可以看到生成了get和set方法。 @EqualsAndHashCode@EqualsAndHashCode注解实现equals()方法和hashCode()方法。hashcode是用于散列数据的快速存取，如利用HashSet/HashMap/Hashtable类来存储数据时，都是根据存储对象的hashcode值来进行判断是否相同的。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Java Web开发--log4j]]></title>
      <url>%2F2016%2F11%2F04%2Flog4j%2F</url>
      <content type="text"><![CDATA[isDebugEnabled在输出日志时，判断输出级别： 123if(logger.isDebugEnabled()) &#123; logger.debug("通用处理，信息为：" + JSON.toJSONString(vehicleLocationData));&#125; 当输出级别是debug，即需要进行日志信息输出时，加不加这句if判断，在效率上几乎没有差别；当输出级别高于debug，即不需要进行日志信息输出时： ①假如debug方法中的参数比较简单时（比如直接就是写好的字符串），加不加这句if判断，在效率上也几乎没有什么差别； ②假如debug方法中的参数比较复杂时（比如还要使用别的函数进行计算、或者还要进行字符串的拼接等等,如上代码片段所示，输出的内容需要序列化），在前面就加上这句if判断，会让效率提高（否则，开始大动干戈做了很多事情（比如字符串的拼接，序列化），后来才发现不需要进行输出日志信息），白白浪费了CPU资源，影响程序的运行效率。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Redis客户端连接]]></title>
      <url>%2F2016%2F11%2F04%2Fredis-client-connect%2F</url>
      <content type="text"><![CDATA[Redis特点 Redis 是一个 key-value 的缓存(cache)和存储(store)系统（现在我们只用它来做缓存，目前还未当作DB用，数据存放在 Cassandra 里） 支持丰富的数据结构，List 就专门用于存储列表型数据，默认按操作时间排序。Sorted Set 可以按分数排序元素，分数是一种广义概念，可以是时间或评分。其次，其丰富的数据结构为日后扩展提供了很大的方便。 提供的所有操作都是原子操作，为并发天然保驾护航。 超快的性能，见其官方性能测试《How fast is Redis?》。 拥有比较成熟的Java客户端 - Jedis，像新浪微博都是使用它作为客户端。（官方推荐的Clients） Redis运行一段时间后，出现错误，无法获得连接： 1redis.clients.jedis.exceptions.JedisException: Could not get a resource from the pool 使用命令查看客户端数量。 1D:\Program Files\Redis&gt;redis-cli.exe info clients 结果如下所示： 12345# Clientsconnected_clients:11client_longest_output_list:0client_biggest_input_buf:0blocked_clients:0 Redis客户端连接在修改了Redis的绑定IP后，用客户端登录需要显示的指定IP和端口： 1./redis-cli -h 192.168.24.252 -p 6379 h代表hostname，主机，p代表port，端口。 Redis是否正确关闭连接可以看出目前的客户端已经超出了最大的客户端数量(配置的是10个)。应该是没有释放连接导致的问题。明显一个请求一次连接是很不靠谱的。这个问题发生有两方面的原因： 未正确使用对象池的空闲队列行为（LIFO“后进先出”栈方式） “关闭集群链接时异常导致连接泄漏”问题 修改配置： 123456789101112131415161718192021private static Dictionary&lt;Integer, JedisPool&gt; pools = new Hashtable();static &#123; JedisPoolConfig config = new JedisPoolConfig(); config.setMaxTotal(200); config.setMaxIdle(50); /*设置最小空闲数,在并发量不高时可以降低最小空闲数*/ config.setMinIdle(8); config.setMaxWaitMillis(10000); config.setTestOnBorrow(true); config.setTestOnReturn(true); //Idle时进行连接扫描 config.setTestWhileIdle(true); //表示idle object evitor两次扫描之间要sleep的毫秒数 config.setTimeBetweenEvictionRunsMillis(30000); //表示idle object evitor每次扫描的最多的对象数 config.setNumTestsPerEvictionRun(10); //表示一个对象至少停留在idle状态的最短时间，然后才能被idle object evitor扫描并驱逐；这一项只有在timeBetweenEvictionRunsMillis大于0时才有意义 config.setMinEvictableIdleTimeMillis(60000); //循环创建16个redis数据库连接池,存放在字典里面 for (int i = 0; i &lt; 2; i++) &#123; JedisPool item = new JedisPool(config, "127.0.0.1", 6379, 0); pools.put(i, item); &#125;&#125; 使用命令client-cli.exe info clients查看客户端的连接数量时，一般为最小空闲连接数量与客户端数量之和。比如查看客户端连接数量为17，设置的最小空闲连接数量是8，有2个连接池，即为16，加一个当前客户端的连接，刚好17个连接。此处Could not get a resource from the pool错误的原因是在打开了连接之后未关闭连接，此处使用的Redis版本为3.2.100 for Windows。 1234567891011121314151617181920212223242526/*** 获取数据** @param key //key* @param db //数据库序号*/public static String get(String key, Integer db) &#123; JedisPool poolItem = pools.get(db); Jedis jredis = null; String result = null; try &#123; jredis = poolItem.getResource(); result = jredis.get(key); &#125; catch (Exception e) &#123; log.error("get value error", e); &#125; finally &#123; if (jredis != null) &#123; /* 关闭Redis连接，ReturnResource方法已经标记为Deprecated 新的关闭连接的方式为直接调用close方法 */ jredis.close(); &#125; &#125; return result;&#125; Redis配置是否正确绑定在Redis的配置文件中： 12345678910111213## ~~~ WARNING ~~~ If the computer running Redis is directly exposed to the# internet, binding to all the interfaces is dangerous and will expose the# instance to everybody on the internet. So by default we uncomment the# following bind directive, that will force Redis to listen only into# the IPv4 lookback interface address (this means Redis will be able to# accept connections only from clients running into the same computer it# is running).## IF YOU ARE SURE YOU WANT YOUR INSTANCE TO LISTEN TO ALL THE INTERFACES# JUST COMMENT THE FOLLOWING LINE.# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~bind 192.168.24.252 bind的地址如果和程序中配置的地址不一致，也会提示此错误。在Linux里，如果没有指定配置文件，则会使用默认的配置文件，所以在修改了配置文件之后，启动Redis服务的时候显示的指定使用修改后的配置文件： 1./redis-server ../redis.conf &amp; 参考资料： Jedis - When to use returnBrokenResource()]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Intellij Idea小技巧(tips)]]></title>
      <url>%2F2016%2F11%2F03%2Fintellij-idea-tips%2F</url>
      <content type="text"><![CDATA[键盘调整Debug窗口的大小键盘调整Debug窗口的大小快捷键是Ctrl + Shift + Up/Down，注意一定要定位到Debug视图，也就是Debug视图但是当前窗口的活跃(Active)视图才会生效。 同理，在调整项目树宽度时，可以使用快捷键Ctrl + Alt + Left/Right。 Debug视图Tab页切换快捷键是Shift + Tab，如下图所示。 Debug视图日志滚动到末尾如果想在Debug视图中将日志始终定位到末尾，可以点击左侧的Scroll To End按钮，也可以使用快捷键Ctrl + End。 Debug视图清空日志清空日志没有快捷键，但是可以使用键盘上的鼠标右键来做到。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Kafka消费position]]></title>
      <url>%2F2016%2F11%2F02%2Fkafka-consume-position%2F</url>
      <content type="text"><![CDATA[kafka允许通过seek(TopicPartition，long)指定新的位置，或者seekToBeginning，seekToEnd定位到最早或最近的offset。注意seek重置offsets只对当前消费者起作用，它并不会触发consumer的rebalance，或者影响其他消费者的fetchOffsets。在大多数情况下，消费者消费记录只是简单地从一开始到结束，并且定时地提交它的位置(不管是自动的还是手动的)。不过新的API也允许消费者手动控制它的位置，消费者可以在一个partition钟随意地往前或者往后移动位置。这就意味着消费者可以重新消费旧的记录(多次读取相同的记录)，或者直接跳到最近的记录，忽略掉中间的记录。 1234567891011121314151617181920212223242526272829/* * 得到分区 * * @param topics * @return void * @throws @author Jiangxiaoqiang * @Title: initialTopicsPartitions */public void initialTopicsPartitions(String[] topics) &#123; if (topics != null &amp;&amp; topics.length &gt; 0) &#123; for (String topic : topics) &#123; if (!Converter.toBlank(topic).equals("")) &#123; topicPartitions.add(new TopicPartition(topic, PublicVariable.KAFKA_COMSUME_PARTION)); &#125;&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD &#125; //从最新的位置开始消费 consumer.seekToEnd(); consumer.assign(topicPartitions);======= &#125; consumer.assign(topicPartitions); /* 从最新的位置开始消费,Special methods for seeking to the earliest and latest offset the server maintains are also available ( seekToBeginning(TopicPartition...) and seekToEnd(TopicPartition...) respectively) */ consumer.seekToEnd();&gt;&gt;&gt;&gt;&gt;&gt;&gt; 2e811b88860dc244827b13d566fed966b8243aaa &#125;&#125;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Redis在Windows下配置]]></title>
      <url>%2F2016%2F11%2F01%2Fredis%2F</url>
      <content type="text"><![CDATA[简介Redis是一个开源的使用ANSI C语言编写、支持网络、可基于内存亦可持久化的日志型、Key-Value数据库，并提供多种语言的API，其实当前最热门的NoSQL数据库之一，NoSQL还包括了Memcached和mongodb。 下载安装下载在这里，这里下载的版本是：Redis-x64-3.2.100.msi。下载完毕后安装即可。安装Redis的目录D:\Program Files\Redis。启动Redis Service服务: 1234#切换到Redis目录cd /d D:\Program Files\Redis#启动Redis服务redis-server.exe redis.windows-service.conf 双击打开 redis-cli.exe , 如果不报错,则连接上了本地服务器,然后测试，比如 set命令，get命令，如下图所示。 Java连接Redis引入Client jar包，在Maven中引入配置： 1234567&lt;dependency&gt; &lt;groupId&gt;redis.clients&lt;/groupId&gt; &lt;artifactId&gt;jedis&lt;/artifactId&gt; &lt;version&gt;2.8.1&lt;/version&gt; &lt;type&gt;jar&lt;/type&gt; &lt;scope&gt;compile&lt;/scope&gt;&lt;/dependency&gt; 编写Java测试代码： 12345678910111213141516package com;import redis.clients.jedis.Jedis;/* * Created by jiangxiaoqiang on 2016/11/1. */public class RedisServiceTest &#123; public static void main(String[] args) &#123; //连接本地的 Redis 服务 Jedis jedis = new Jedis("localhost"); System.out.println("Connection to server sucessfully"); //查看服务是否运行 System.out.println("Server is running: "+jedis.ping()); &#125;&#125; 连接123456789101112static &#123; JedisPoolConfig config = new JedisPoolConfig(); config.setMaxIdle(2); config.setMaxTotal(10); config.setTestOnBorrow(true); config.setMaxWaitMillis(2000); //循环创建16个redis数据库连接池,存放在字典里面 for (int i = 0; i &lt; 16; i++) &#123; JedisPool item = new JedisPool(config, "127.0.0.1", 6379,10*1000); pools.put(i, item); &#125;&#125;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[she]]></title>
      <url>%2F2016%2F11%2F01%2Fshe%2F</url>
      <content type="text"><![CDATA[like: 鱼(Fish) 广味香肠 节目 《真正男子漢》(Takes a Real man) dislike: 生食(日本料理),可以少量吃北极贝和甜虾]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Kafka常用操作]]></title>
      <url>%2F2016%2F10%2F29%2Fkafka-common-operation%2F</url>
      <content type="text"><![CDATA[启动kafka： 1./kafka-server-start.sh ../config/server.properties &amp; 创建主题： 1./kafka-topics.sh --zookeeper localhost:2181 --create --topic test1 --partitions 1 --replication-factor 1 --config max.message.bytes=64000 --config flush.messages=1 查看所有主题： 1./kafka-topics.sh --list --zookeeper 192.168.24.11:2181 删除主题： 1./kafka-topics.sh --zookeeper 192.168.24.244:2181 --delete --topic 0085000 消费主题： 12345# 从开始处消费主题./kafka-console-consumer.sh --zookeeper localhost:2181 --from-beginning --topic 0085000# 从最新位置消费主题./kafka-console-consumer.sh --zookeeper localhost:2181 --topic 0085000 改变主题L000000的默认分区数： 1/kafka-topics.sh --zookeeper 192.168.24.238:2181,192.168.24.11:2181,192.168.24.71:2181 --alter --topic L000000 --partitions 2]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Kafka彻底删除主题]]></title>
      <url>%2F2016%2F10%2F29%2Fkafka-delete-topic%2F</url>
      <content type="text"><![CDATA[这里的Kafka的版本是0.9.0.1，查看所有Topics和分区： 1./kafka-topics.sh --describe --zookeeper 192.168.244.11:2181 只查看所有Topic： 1./kafka-topics.sh --list --zookeeper 192.168.24.244:2181 删除主题： 1./kafka-topics.sh --zookeeper 192.168.24.244:2181 --delete --topic 0085000 删除主题并不是真正的删除，仅仅是标记为删除(marked for deletion)，如果想彻底删除主题，可以修改kafka的配置： 1delete.topic.enable=true 删除Kafka存储目录(server.properties文件log.dirs配置，默认为”/tmp/kafka-logs”)相关topic目录。配置了delete.topic.enable=true直接通过命令删除，如果命令删除不掉，直接通过zookeeper-client删除掉broker下的topic即可。登录ZooKeeper客户端： 1234567891011#切换到ZooKeeper目录cd /usr/hdp/2.4.3.0-227/zookeeper/bin#登录ZooKeeper客户端./zookeeper-client#找到topic所在的目录ls /brokers/topics#彻底删除topic(remove recursively)rmr /brokers/topics/0085000 如果不知道ZooKeeper客户端的目录，可以通过如下命令找到。 1find / -name zookeeper-client]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Kafka常见错误]]></title>
      <url>%2F2016%2F10%2F28%2Fkafka-error%2F</url>
      <content type="text"><![CDATA[Invalid partition given with record在Kafka生产者里写入消息时，提示写入失败，详细的错误信息如下所示： 123456789[ERROR]-[2016年-10月-28日16:17:35.083]-[Thread-25]-[com.zw.socket.service.kafka.producer.ClientKafkaProducer]-&#123;生产者发送消息出错&#125;java.lang.IllegalArgumentException: Invalid partition given with record: 1 is not in the range [0...1]. at org.apache.kafka.clients.producer.KafkaProducer.partition(KafkaProducer.java:671) ~[kafka-clients-0.9.0.1.jar:?] at org.apache.kafka.clients.producer.KafkaProducer.send(KafkaProducer.java:430) ~[kafka-clients-0.9.0.1.jar:?] at org.apache.kafka.clients.producer.KafkaProducer.send(KafkaProducer.java:339) ~[kafka-clients-0.9.0.1.jar:?] at com.zw.socket.service.kafka.producer.ClientKafkaProducer.sendMessage(ClientKafkaProducer.java:102) [classes/:?] at com.zw.socket.service.handler.common.CommonCommandHandler.commonMessageWriteIntoKafka(CommonCommandHandler.java:95) [classes/:?] at com.zw.socket.service.handler.device.DeviceMessageHandler.sendRegisterResult(DeviceMessageHandler.java:175) [classes/:?] at com.zw.socket.service.handler.device.DeviceMessageHandler.isAllowRegisted(DeviceMessageHandler.java:161) [classes/:?] at com.zw.socket.service.handler.device.DeviceMessageHandler.saveDeviceInfo(DeviceMessageHandler.java:216) [classes/:?] 在Kafka的配置文件中，修改Kafka每个topic的默认分区数的配置： 12#每个topic的分区个数，更多的partition会产生更多的segment filenum.partitions=2 The group coordinator is not available1234562016-10-29 14:52:56.387 INFO [nioEventLoopGroup-3-1][org.apache.kafka.common.utils.AppInfoParser$AppInfo:82] - Kafka version : 0.9.0.12016-10-29 14:52:56.387 INFO [nioEventLoopGroup-3-1][org.apache.kafka.common.utils.AppInfoParser$AppInfo:83] - Kafka commitId : 23c69d62a0cabf062016-10-29 14:52:56.409 ERROR [nioEventLoopGroup-3-1][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$DefaultOffsetCommitCallback:489] - Offset commit failed.org.apache.kafka.common.errors.GroupCoordinatorNotAvailableException: The group coordinator is not available.2016-10-29 14:52:56.519 WARN [kafka-producer-network-thread | producer-1][org.apache.kafka.clients.NetworkClient$DefaultMetadataUpdater:582] - Error while fetching metadata with correlation id 0 : &#123;0085000=LEADER_NOT_AVAILABLE&#125;2016-10-29 14:52:56.612 WARN [pool-6-thread-1][org.apache.kafka.clients.NetworkClient$DefaultMetadataUpdater:582] - Error while fetching metadata with correlation id 1 : &#123;0085000=LEADER_NOT_AVAILABLE&#125; 产生问题具体原因不详，可能是修改了默认分区导致的，解决方法：停止Kafka Broker，登录ZooKeeper客户端，删除所有主题即可。 1234567891011#切换到ZooKeeper目录cd /usr/hdp/2.4.3.0-227/zookeeper/bin#登录ZooKeeper客户端./zookeeper-client#找到topic所在的目录ls /brokers/topics#彻底删除topicrmr /brokers/topics/0085000 无法往集群中写入数据检查部署服务器节点，也就是写入节点的/etc/hosts配置文件中是否有IP和主机名的映射。 1vim /etc/hosts 配置如下： 12345127.0.0.1 localhost localhost.localdomain localhost4 localhost4.localdomain4::1 localhost localhost.localdomain localhost6 localhost6.localdomain6192.168.24.136 节点1主机名192.168.24.137 节点2主机名192.168.24.244 localhost Consumer Marking the coordinator XXXXX deadMarking the coordinator dead happens when there is a Network communication error between the Consumer Client and the Coordinator (Also this can happen when the Coordinator dies and the group needs to rebalance). There are a variety of situations (offset commit request, fetch offset, etc) that can cause this issue. I will suggest that you research what’s causing this situations。解决此问题，重新启动消费者/生产者。 LEADER_NOT_AVAILABLE在Kafka消费数据时，提示如下错误： 114:37:19.717]-[Thread-24]-[org.apache.kafka.clients.NetworkClient]-&#123;Error while fetching metadata with correlation id 63 : &#123;0402080=LEADER_NOT_AVAILABLE, T16092920=LEADER_NOT_AVAILABLE, TH003086=LEADER_NOT_AVAILABLE, 65565665666=LEADER_NOT_AVAILABLE, 0146636=LEADER_NOT_AVAILABLE, 16687896589=LEADER_NOT_AVAILABLE, CQSZ=LEADER_NOT_AVAILABLE, 25698568=LEADER_NOT_AVAILABLE, 1037494=LEADER_NOT_AVAILABLE, 1551555=LEADER_NOT_AVAILABLE, 0085000=LEADER_NOT_AVAILABLE, L000010=LEADER_NOT_AVAILABLE, 145263078=LEADER_NOT_AVAILABLE&#125;&#125; 重新启动生产者即可。KafkaProducer/Sender都需要获取集群的配置信息Metadata。所谓Metadata，Topic/Partion与broker的映射关系：每一个Topic的每一个Partion，得知道其对应的broker列表是什么，其中leader是谁，follower是谁。Sender从集群获取信息，然后更新Metadata； KafkaProducer先读取Metadata，然后把消息放入队列。如果没有获取到相应的元素据(Metadata)，则会有如下错误：fetching topic metadata for topics from broker failed。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[HP KU 1158键盘]]></title>
      <url>%2F2016%2F10%2F27%2Fnew-keyboard%2F</url>
      <content type="text"><![CDATA[以前的旧键盘打字的声音有点大，中午打字都担心吵到旁边休息的同学，而且按键比较生硬，今天特意请飞哥换了一款键盘HP KU 1158，确实好用不少。一直在找一款适合长时间输入的键盘，而且要求声音要尽量小一些，价格平民化一些(Realforce一千多也还蛮贵的)。这款键盘符合要求。 Amaozn购买链接.]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[WebSocket连接(SessionConnectEvent)、断开连接(SessionDisconnectEvent)事件]]></title>
      <url>%2F2016%2F10%2F27%2Fwebsocket-event%2F</url>
      <content type="text"><![CDATA[WebSocket事件：SessionConnectEvent(连接时), SessionConnectedEvent(连接后), SessionDisconnectEvent(断开连接)。 12345678public class WebSocketDisconnectHandler implements ApplicationListener&lt;SessionDisconnectEvent&gt; &#123; @Override public void onApplicationEvent(SessionDisconnectEvent sessionDisconnectEvent) &#123; StompHeaderAccessor stompHeaderAccessor = StompHeaderAccessor.wrap(sessionDisconnectEvent.getMessage()); //do something &#125;&#125; 添加了断开连接实现类后的逻辑后，还需要注入Bean，否则不会生效。在相关配置文件(spring-socket-servlet.xml)中增加如下配置即可。 1&lt;bean class="com.zw.socket.service.config.WebSocketDisconnectHandler"&gt;&lt;/bean&gt;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Stomp + WebSocket消息实时推送]]></title>
      <url>%2F2016%2F10%2F25%2Fstomp-spring-message-push%2F</url>
      <content type="text"><![CDATA[消息广播消息广播将消息发送给所有用户。 12345678/* * 推送给所有用户 */private void pushInfoImpl(String url, String content) &#123; if (simpMessagingTemplate != null) &#123; simpMessagingTemplate.convertAndSend(url, content); &#125;&#125; 推送给指定用户12345678/* * 推送给指定用户 */private void pushInfoImpl(String user, String url, String content) &#123; if (simpMessagingTemplate != null) &#123; simpMessagingTemplate.convertAndSendToUser(user, url, content); &#125;&#125; url直接为/location，在发给客户端的时，会自动添加user前缀和用户名，客户端订阅的url像这样：/user/admin/location，订阅的url中，不包含topic。content为需要发送的消息的内容。 客户端客户端订阅消息如下代码片段所示： 123stompClient.subscribe('/user/admin/location/', function (greeting) &#123; console.log('接收到订阅的信息：' + greeting.body);&#125;); 客户端订阅的URL中，admin是用户名。发送给指定用户时会默认添加user前缀。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[SQuirreL GUI客户端集成Phoenix、MySQL配置]]></title>
      <url>%2F2016%2F10%2F25%2Fsquirrel-phoenix-configuration%2F</url>
      <content type="text"><![CDATA[SQuirreL GUI客户端简介SQuirreL GUI客户端来连接Phoenix，就像MySQL使用Navicat for MySQL，Oracle使用PL/SQL Developer一样，在进行一些数据库操作的时候能够更加的直观和方便。同时它还可以连接MySQL。 下载并安装SQuirreL GUI下载好的文件是一个压缩包(squirrel-sql-3.7.1-standard.zip)。不用解压缩，直接修改文件的后缀名为jar(squirrel-sql-3.7.1-standard.jar)，双击即可打开安装界面。如果无法双击打开，则可以通过命令行的方式打开： 1java -jar squirrel-sql-3.7-standard.jar 下载驱动到Phoenix镜像站点下载包，这里选择的是apache-phoenix-4.8.0-HBase-1.2-bin.tar.gzip，到解压的apache-phoenix-4.8.0-HBase-1.2-bin.tar.gzip包的主目录下，将如下几个jar包拷贝到SQuirreL安装目录的lib目录下，例如本机路径是D:\Program Files\squirrel-sql-3.7.1\lib。 1phoenix-4.8.0-HBase-1.2-client.jar 注意顺序，先拷贝jar包，在启动SQuirreL添加驱动，如果是拷贝jar包时已经启动了SQuirreL，那么SQuirreL需要重启一下，拷贝的jar包才生效，这个是需要注意的地方，可以参见SQuirreL Configure: could not initial class org.apache.phoenix.jdbc.PhoenixDriver。 添加Driver添加Driver如下图所示。 Name填写用户自定义名称。Example URL填写ZooKepper地址。Class Name填写：org.apache.phoenix.jdbc.PhoenixDriver。 添加Alias连接Hbase如下图所示。 Name是Alias的名字，可以填写自定义名称。Driver选择上一步配置好的Driver名称，这里是Phoenix。url填写Phoenix连接串：jdbc:phoenix:192.168.24.226,192.168.24.195:2181:/hbase-unsecure。UserName和Password填写操作系统的登录用户和登录密码。 查询SQL查询如下图所示。 连接MySQL将MySQL的驱动mysql-connector-java-5.1.39.jar拷贝到lib目录下。 驱动链接填写：jdbc:mysql://192.168.24.234:3306/clbs?useUnicode=true&amp;characterEncoding=utf-8。用户名和密码填写登录Linux主机的用户名和密码。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Fedora快捷键]]></title>
      <url>%2F2016%2F10%2F21%2FFedora-shortkey%2F</url>
      <content type="text"><![CDATA[如下是我在使用Fedora的时候整理的快捷键，网络上有许多快捷键版本，下表是经过测试可用并一直在使用的快捷键。 快捷键 作用 Windows + A 显示软件列表 Windows + H 隐藏当前窗口 Alt + F10 最大化、还原当前窗口 Ctrl + Alt + Up/Down 切换当前窗口 Alt + Tab 应用程序之间进行切换 Windows + Left/Right/Up/Down 将窗口移向左右、最大化、还原 Windows + PageUp/PageDown 切换工作区]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Spring模块化配置]]></title>
      <url>%2F2016%2F10%2F21%2Fspring-module-config%2F</url>
      <content type="text"><![CDATA[Spring的一大缺点就是配置文件非常多，想象如果没有注解扫描Bean，所有的Bean都配置在XML文件中，将会是一个噩梦，项目中会充斥着大量的配置文件。这也是Spring-Boot项目所要避免的问题之一，在做项目开发时，为了使配置显得有条理化，易于理解，可以采用Spring Import配置文件，项目中需要一个Spring的主文件，在Web.xml中指定Spring的主文件位置，主文件再Import各类配置文件。指定主文件如下代码片段所示： 1234&lt;context-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:spring-config/spring-main-config.xml&lt;/param-value&gt;&lt;/context-param&gt; 其中spring-main-config.xml即是项目的Spring配置主文件。classpath是指WEB-INF文件夹下的classes目录,classpath 和 classpath 区别是：classpath：只会到你的class路径中查找找文件;classpath：不仅包含class路径，还包括jar文件中(class路径)进行查找.在部署完毕的WEB项目中，一般包含WEB-INF和META-INF文件夹。META-INF相当于一个信息包，目录中的文件和目录获得Java 2平台的认可与解释，用来配置应用程序、扩展程序、类加载器和服务manifest.mf文件，在用jar打包时自动生成。其中主配置文件中使用Import Resource如下代码片段所示： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:aop="http://www.springframework.org/schema/aop" xmlns:context="http://www.springframework.org/schema/context" xmlns:util="http://www.springframework.org/schema/util" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop.xsd http://www.springframework.org/schema/util http://www.springframework.org/schema/util/spring-util.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd"&gt; &lt;description&gt;spring主配置文件&lt;/description&gt; &lt;!-- 属性和配置文件读入 ,多个用逗号隔开 数据库参数和系统参数 --&gt; &lt;util:properties id="applicationProperties" location="classpath:application.properties" /&gt; &lt;context:property-placeholder properties-ref="applicationProperties" ignore-resource-not-found="true" /&gt; &lt;!-- 扫描注解@Component , @Service , @Repository。--&gt; &lt;context:component-scan base-package="main.src.*"&gt; &lt;context:include-filter type="annotation" expression="org.aspectj.lang.annotation.Aspect" /&gt; &lt;context:exclude-filter type="annotation" expression="org.springframework.stereotype.Controller" /&gt; &lt;context:exclude-filter type="annotation" expression="org.springframework.web.bind.annotation.RestController" /&gt; &lt;context:exclude-filter type="annotation" expression="org.springframework.web.bind.annotation.ControllerAdvice" /&gt; &lt;/context:component-scan&gt; &lt;!--aop 注解风格支持 proxy-targer-class默认false,用jdk动态代理,true是cglib .expose-proxy当前代理是否为可暴露状态,值是"ture",则为可访问。 --&gt; &lt;aop:aspectj-autoproxy expose-proxy="true" proxy-target-class="true" /&gt; &lt;!--aop xml风格支持 --&gt; &lt;aop:config expose-proxy="true" proxy-target-class="true" /&gt; &lt;!-- 导入其它spring配置文件 --&gt; &lt;import resource="classpath:spring-config/spring-filters.xml" /&gt; &lt;import resource="classpath:spring-config/spring-datasource.xml" /&gt; &lt;import resource="classpath:spring-config/spring-mybatis.xml" /&gt; &lt;import resource="classpath:spring-config/spring-cache.xml" /&gt; &lt;import resource="classpath:spring-config/spring-i18n.xml" /&gt; &lt;import resource="classpath:spring-config/spring-json.xml" /&gt; &lt;import resource="classpath:spring-config/spring-security.xml" /&gt; &lt;import resource="classpath:spring-config/spring-exception.xml" /&gt; &lt;import resource="classpath:spring-config/spring-log.xml" /&gt; &lt;import resource="classpath:spring-config/spring-validator.xml" /&gt; &lt;import resource="classpath:spring-config/spring-quartz.xml" /&gt; &lt;import resource="classpath:spring-config/spring-socket-servlet.xml"/&gt;&lt;/beans&gt;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Stomp WebSocket路由]]></title>
      <url>%2F2016%2F10%2F20%2Fstomp-url-route%2F</url>
      <content type="text"><![CDATA[STOMP即Simple (or Streaming) Text Orientated Messaging Protocol，简单(流)文本定向消息协议，它提供了一个可互操作的连接格式，允许STOMP客户端与任意STOMP消息代理（Broker）进行交互。STOMP协议由于设计简单，易于开发客户端，因此在多种语言和多种平台上得到广泛地应用。WebSocket协议的应用层子协议STOMP（流文本定向消息协议）。在应用中直接使用WebSocket API显得有些低端，直到统一标准规范时也只有一小部分框架可以解析信息或通过注解方式使用它。这正是考虑在应用中运用子协议和产生基于WebSocket支持的Spring的STOMP的原因。当运用一个上层协议，WebSocket API的细节就显得不那么重要了，正如运用了HTTP后TCP的通信细节不再暴漏在应用中一样。STOMP是为了简单而创建的一种消息协议。它基于模仿HTTP协议的帧。帧由一个命令、可选的头和可选的体组成。 业务中需要实现不同的消息类别分发，在客户端进行不同的处理。此时想到Stomp的路由。 服务端启动代理中继1234567891011121314151617181920212223@Configuration@EnableWebSocketMessageBrokerpublic class WebSocketConfig extends AbstractWebSocketMessageBrokerConfigurer &#123; @Override public void configureMessageBroker(MessageBrokerRegistry config) &#123; /** * 启用了STOMP代理中继功能：并将其目的地前缀设置为 "/topic"； * spring就能知道 所有目的地前缀为"/topic" 的消息都会发送到STOMP代理中； */ config.enableSimpleBroker("/topic"); /** * 设置了应用的前缀为"app"：所有目的地以"/app"打头的消息（发送消息url not连接url） * 都会路由到带有@MessageMapping注解的方法中，而不会发布到代理队列或主题中； */ config.setApplicationDestinationPrefixes("/app"); &#125; @Override public void registerStompEndpoints(StompEndpointRegistry registry) &#123; registry.addEndpoint("/gs-guide-websocket").withSockJS(); &#125;&#125; 或者以XML文件的方式进行配置，两者是等价的： 1234567891011121314151617&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:websocket="http://www.springframework.org/schema/websocket" xsi:schemaLocation=" http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/websocket http://www.springframework.org/schema/websocket/spring-websocket.xsd"&gt; &lt;websocket:message-broker application-destination-prefix="/app"&gt; &lt;websocket:stomp-endpoint path="/gs-guide-websocket"&gt; &lt;websocket:sockjs/&gt; &lt;/websocket:stomp-endpoint&gt; &lt;websocket:simple-broker prefix="/topic, /queue"/&gt; &lt;/websocket:message-broker&gt;&lt;/beans&gt; 服务端添加ControllerSpring官方的例子演示了Send-Response模型，如果需要请求之后，服务端多次推送消息，主动推送消息，可采用如下方式： 12345678910111213141516@Controllerpublic class GreetingController &#123; public SimpMessagingTemplate template; @Autowired public GreetingController(SimpMessagingTemplate template) &#123; this.template = template; &#125; @MessageMapping("/hello") @SendTo("/topic/greetings") public void greeting(HelloMessage message) throws Exception &#123; template.convertAndSend("/topic/greetings", "aaaaaaa"); &#125;&#125; SimpMessagingTemplate是Spring实现的一个发送模板类，直接自动注入获取相应实例即可。SimpMessagingTemplate实例可以实现服务端主动向客户端订阅的Url推送消息。第一个参数为推送地址，第二个参数为需要推送的消息内容。 浏览器端1234567891011function connect() &#123; var socket = new SockJS('/clbs/gs-guide-websocket'); stompClient = Stomp.over(socket); stompClient.connect(&#123;&#125;, function (frame) &#123; setConnected(true); console.log('Connected: ' + frame); stompClient.subscribe('/topic/greetings', function (greeting) &#123; console.log(greeting.body); &#125;); &#125;);&#125; clbs是项目名称，gs-guide-websocket是终结点名称。greeting.body是取出服务端响应的消息体(Message Body)。Stomp协议与HTTP协议有许多相似之处，命令 + 消息头 + 空行 + 消息体。 1stompClient.send("/app/gs-guide-websocket/location",&#123;&#125;,JSON.stringify(requestStr)); STOMP Over WebSocket WebSocket Support]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[expected single matching bean but found 2]]></title>
      <url>%2F2016%2F10%2F20%2Fspring-encount-error%2F</url>
      <content type="text"><![CDATA[在WebSocket往客户端推送消息的开发过程中，获取推送消息实例SimpMessagingTemplate时，错误如下： 1[ERROR]-[2016年-10月-19日17:53:25.026]-[RMI TCP Connection(2)-127.0.0.1]-[org.springframework.web.context.ContextLoader]-&#123;Context initialization failed&#125; org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name &apos;com.zw.socket.service.controller.InstanceMessageController#0&apos; defined in class path resource [spring-config/spring-socket-servlet.xml]: Unsatisfied dependency expressed through constructor parameter 0; nested exception is org.springframework.beans.factory.NoUniqueBeanDefinitionException: No qualifying bean of type [org.springframework.messaging.simp.SimpMessagingTemplate] is defined: expected single matching bean but found 2:org.springframework.messaging.simp.SimpMessagingTemplate#0,brokerMessagingTemplate 发生此错误的原因是在配置文件spring-socket-servlet.xml里重复做了如下配置： 123456789&lt;websocket:message-broker application-destination-prefix="/app"&gt; &lt;websocket:stomp-endpoint path="/vehicle"&gt; &lt;websocket:handshake-interceptors&gt; &lt;bean class="org.springframework.web.socket.server.support.HttpSessionHandshakeInterceptor"/&gt; &lt;/websocket:handshake-interceptors&gt; &lt;websocket:sockjs session-cookie-needed="true" /&gt; &lt;/websocket:stomp-endpoint&gt; &lt;websocket:simple-broker prefix="/topic"/&gt;&lt;/websocket:message-broker&gt; 扫描配置文件时会自动生成一个brokerMessagingTemplate实例，与实例simpMessagingTemplate冲突。解决的方法就是去掉配置文件中的配置。 参考： Could not autowire. No beans of SimpMessagingTemplate type found]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Spring Bean是否注册判断]]></title>
      <url>%2F2016%2F10%2F18%2Fspring-bean-registered%2F</url>
      <content type="text"><![CDATA[在项目的开发过程中有许多Bean，怎么判断一个Bean是否已经纳入容器管理了呢？当然最直接的方式是直接使用，如果不能用，那么肯定就未注册成功，但是也有的情况不是那么明显的，即使没有注册成功也不会有明显的错误。如何有效的鉴别和判断是否已经注册？ 日志在项目启动时会输出日志，提示注册了哪些Bean，那么只需要使用Bean的名称，在日志里面搜索一遍，即可知晓Bean是否已经注册，如果有相关注册成功输出提示，那么代表注册OK，如果没有相关日志，此时就需要排查Bean的配置了。 方法获取Bean可以通过如下方法获取特定注解的Bean的集合： 1Map&lt;String,Object&gt; beans = applicationContext.getBeansWithAnnotation(Foo.class); 其中Foo代表@Autowired、@Controller等等注解。 Is there any way to query bean of spring container]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Spring线程中Bean注入问题]]></title>
      <url>%2F2016%2F10%2F18%2Fspring-get-bean%2F</url>
      <content type="text"><![CDATA[实现ApplicationContextAware在Spring中开启线程时，无法使用Bean的自动注入，此时需要手动获取Bean。方法如下： 12345678910111213141516public class SpringApplicationContextHolder implements ApplicationContextAware &#123; private static ApplicationContext context; @Override public void setApplicationContext(ApplicationContext context) throws BeansException &#123; SpringApplicationContextHolder.context = context; &#125; public static Object getSpringBean(String beanName) &#123; return context == null ? null : context.getBean(beanName); &#125; public static String[] getBeanDefinitionNames() &#123; return context.getBeanDefinitionNames(); &#125;&#125; 配置文件注册在Spring中注册工具类的bean： 1&lt;bean class="com.zw.socket.service.kafka.comsumer.SpringApplicationContextHolder"&gt;&lt;/bean&gt; 获取Bean获取Bean实例： 1ClientMessageTransfer clientMessageTransfer=(ClientMessageTransfer)SpringApplicationContextHolder.getSpringBean("clientMessageTransfer");]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[port aready in use]]></title>
      <url>%2F2016%2F10%2F17%2Fport-aready-in-use%2F</url>
      <content type="text"><![CDATA[在使用Intellij Idea调试时，以Application方式启动程序时提示： 123456789101112132016-10-17 11:28:38.537 ERROR 23156 --- [ main] o.s.b.d.LoggingFailureAnalysisReporter : ***************************APPLICATION FAILED TO START***************************Description:The Tomcat connector configured to listen on port 8080 failed to start. The port may already be in use or the connector may be misconfigured.Action:Verify the connector&apos;s configuration, identify and stop any process that&apos;s listening on port 8080, or configure this application to listen on another port. 提示8080端口已经被占用了，由于此时是以Application方式启动的，没有Tomcat的相关端口配置。Spring Boot uses embedded Tomcat by default, but it handles it differently without using tomcat-maven-plugin. To change the port use –server.port parameter for example。添加程序启动参数：–server.port=8181，更改嵌入的Tomcat的端口即可解决此问题。如图所示： 解决方案来自StackOverflow： Launching Spring application Address already in use]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Fedora 24搭建Git Server]]></title>
      <url>%2F2016%2F10%2F16%2Ffedora-git-server%2F</url>
      <content type="text"><![CDATA[想将代码拷贝到家里的电脑，在安静的时刻可以阅读消化。每天用U盘拷贝也是比较麻烦，本来Github挺好用的，但是闭源的托管需要费用。刚好办公电脑和家里的电脑安装了OpenVPN,所以就想在家里的电脑搭建一个Git Server，通过OpenVPN将家里的电脑和办公电脑相连(相当于局域网)。这样就可以随时提交代码了。同时也想以SSH连接家里的电脑，所以同时也安装了OpenSSH。也可以SSH远程Copy，但是无法增量Copy，Copy一次大概需要2-3个小时。遂放弃SSH Copy的方案。 启动SSH服务确定是否已经安装SSH服务： 1rpm -qa | grep openssh-server 如果没有安装服务，输入如下命令安装： 1dnf install openssh-server -y 修改配置文件: 1vi /etc/ssh/sshd_config 1234#Port 22 监听的端口号，默认是22，可以自定义。#Protocol 2 支持的协议，默认就好，不用修改#PermitRootLogin yes 是否允许root直接登录，最好设置为no#MMaxAuthTries 6 最大登录数，默认是6，建议设置为3，防止别人密码穷举。 修改完配置后，重启SSH服务： 1service ssh restart 查看SSH服务状态: 1service sshd status 允许此端口（22）访问： 1iptables -A INPUT -p tcp --dport 22 -j ACCEPT 初始化Git仓库先在Fedora机器上，选定一个目录作为Git仓库，这里选择的是 1/home/dolphin/dolphin/source/zwlbs/plateform3.0/zwlbs.git 在目录下输入命令： 1$ sudo git init --bare zwlbs.git 签出Git库在办公的电脑上输入如下命令签出Git仓库： 1git clone dolphin@10.0.0.6:/home/dolphin/dolphin/source/zwlbs/plateform3.0/zwlbs.git 签出时会提示确定指纹，选择yes，同时需要输入用户dolphin的密码，输入即可。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[在Fedora 24中使用xx-net]]></title>
      <url>%2F2016%2F10%2F15%2FFedora-24-using-xxnet%2F</url>
      <content type="text"><![CDATA[虽然此处实际在Linux平台进行的配置，但是XX-Net是跨平台的，在Windows、Mac OS下一样可以使用，在其他的操作系统下配置类似。在Fedora 24中安装完Google Chrome之后，还需要同步在Windows平台上保存的Google Chrome的书签（里面有好多收藏的好网站）、Cookie(不用每次登陆网页输入用户名和密码，记忆用户名和密码非常具有迷惑性，目前注册的用户名密码真的太多了，根本记不住，现在都是借助KeePass来记忆)等等数据。平时的搜索还是需要用Google，Google相比于百度，搜索出的结果更加精确，内容对于用户更加有意义。当你迫切想要知道某个问题的思路时，如果搜索出来一些无关痛痒的内容，是非常浪费时间的，消磨你的意志，会让你有一种被掏空了的感觉，对就是那种感觉。极大的降低了效率，想想如此庞大的用户基数，如果搜索出的内容不精准、没有意义所造成的资源浪费（时间、精力、意志力等）是非常恐怖的。所以这也是为什么费尽心思要使用Google，当你顺利的找到自己想要的内容并快速完成任务时，会深刻的体会到前期在科学上网里花费的时间是值得的。要做到以上两点，就需要借助XX-Net。 xx-net简介XX-Net是一款让你可以让你提高工作效率的工具，它通过让你可以获取到更多的信息的方式达到。XX-Net is a free desktop application that delivers fast, reliable and secure access to the open Internet for users in censored regions. It uses google app engine (GAE:Google App Engine) as a proxy server through the firewall.截至目前，xx-net在Github上(全球最大的同性交友网站)已经有10000+的star和1000+的watch。 下载xx-net下载在Github.这里下载的是稳定版(Stable Version). 启动xx-net下载完毕后,解压文件夹，在终端中切换到解压的文件夹下，运行启动命令。如果是在Windows下，运行start.vbs。 1./start 配置配置主要分为两步，第一步是安装代理自动切换插件，第二步是导入证书。 安装代理切换插件打开Google Chrome浏览器，切换到插件管理页面,可以选择Settings-Extensions,也可以访问链接：chrome://extensions/，将文件/opt/xx-net/SwitchyOmega/SwitchyOmega.crx托放到浏览器中，即可安装代理自动切换插件SwitchyOmega。 导入证书在Google Chrome浏览器中，访问地址： 1chrome://settings/certificates 选择Authorities选项卡，选择导入(Import)证书。如下图所示。 证书导入完成后在浏览器中访问地址： 1localhost:8085 出现如下图所示页面表示导入成功。 验证配置并使用访问Google搜索引擎，如果能够成功访问Google,代表配置成功。如果首次无法访问，可以待后台程序多运行一些时间，几十分钟到几小时不等。一段时间之后再次尝试。需要注意的是XX-Net代理上网不具有匿名性，或者说匿名性很弱。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Linux开机自动启动程序]]></title>
      <url>%2F2016%2F10%2F14%2Fscript-startup-with-linux%2F</url>
      <content type="text"><![CDATA[开机时自动运行一般有守护进程的服务在Fedora 24中都可以通过systemctl命令自动运行。 1systemctl enable ServiceName 对于没有服务的程序，如果想在开机时随系统启动可以通过脚本来实现。 1nohup openvpn /etc/openvpn/client.conf 添加nohup后台启动，避免父进程结束的时候一并结束子进程。在/etc/rc.d/rc.local脚本中加入如下命令： 1/etc/openvpn/startopenvpn.sh 0:Halt 1:Single-user mode 2:Multi-user mode 3:Multi-user mode with networking 4:Not used/user-definable 5:Start the system normally with appropriate display manager (with GUI) 6:Reboot 登录后自动运行程序用户登录时，bash首先自动执行系统管理员建立的全局登录script ：/etc/profile。然后bash在用户起始目录下按顺序查找三个特殊文件中的一个：/.bash_profile、/.bash_login、/.profile，但只执行最先找到的 一个。因此，只需根据实际需要在上述文件中加入命令就可以实现用户登录时自动运行某些程序（类似于DOS下的 Autoexec.bat）。简单的方法,在/etc/inittab 结尾加上你要启动的程序。/etc/profile： 此文件为系统的每个用户设置环境信息,当用户第一次登录时,该文件被执行。/etc/bashrc: 为每一个运行bash shell的用户执行此文件。~/.bashrc: 当登录时以及每次打开新的shell时,该文件被执行。设置登陆时启动OpenVPN,在/etc/profile文件中添加执行脚本： 1/etc/openvpn/startopenvpn.sh &amp; &gt;&gt; /tmp/openvpn.log 其中startopenvpn.sh脚本中： 12cd /etc/openvpnnohup openvpn /etc/openvpn/client.conf 需要注意的是，执行时需要切换到/etc/openvpn目录，默认的配置文件例如key等默认在当前目录下寻找。OpenVPN启动时需要root权限。需要成功启动OpenVPN客户端首次登陆时需要以root用户登陆。 联网后自动运行程序网络连接建立后运行的脚本可以实现诸多实用功能，如动态域名绑定、连接VPN、上网认证等。实现这一目标的大体思路有两种：在基于NetworkManager的系统中，可配置其dispatcher脚本；Fedora对这一功能支持的不是很好，只能在网络连接建立后运行一个脚本，即/sbin/ifup-local。这个文件默认不存在，需要手动创建。下面的例子用vi编辑/创建这个文件，并添加执行权限。 12vi /sbin/ifup-localchmod 755 /sbin/ifup-local Runlevel]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Java 8 使用Stream API]]></title>
      <url>%2F2016%2F10%2F14%2Fjava-8-using-stream-api%2F</url>
      <content type="text"><![CDATA[遍历集合中的列Stream是Java8中，操作集合的一个重要特性。这里要遍历集合中对象的某一个属性，并取出来用“，”拼接成字符串，传统的写法是写循环遍历每个对象，从中取出某一个属性，进行拼接操作。在Java 8里可以使用Stream API只需要一行代码，非常简洁。 1234List&lt;WorkDayDataInfo&gt; workDayDataInfo = workDayInfos.get(currentWorkDay).getDatas();String assignmentIdStream = assignments.stream() .map(p -&gt; p.getId()) .collect(Collectors.joining(",")); 对于基本数据类型的拼接： 12List&lt;Integer&gt; numbers = Arrays.asList( 4, 8, 15, 16, 23, 42 );return numbers.stream().map( n -&gt; n.toString() ).collect( Collectors.joining( "," ) ); 去List除重复数据去除List中对象的重复数据。 1List&lt;ClientVehicleInfo&gt; distinctVehicles = clientVehicleInfos.stream().distinct().collect(Collectors.toList()); 对于Stream中包含的元素进行去重操作（去重逻辑依赖元素的equals方法），新生成的Stream中没有重复的元素。（根据.equals行为排除所有重复的元素。） 去除String数组重复数据其中deviceNumbers为String类型的数组。 1deviceNumbers= new HashSet&lt;&gt;(Arrays.asList(deviceNumbers)).toArray(new String[0]);]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[linux中的chkconfig、service和systemctl]]></title>
      <url>%2F2016%2F10%2F13%2Flinux-chkconfig-service-systemctl%2F</url>
      <content type="text"><![CDATA[最近在Fedora里使用开机自动启动命令时，提示如下： 1234567Note: This output shows SysV services only and does not include native systemd services. SysV configuration data might be overridden by native systemd configuration. If you want to list systemd services use &apos;systemctl list-unit-files&apos;. To see services enabled on particular target use &apos;systemctl list-dependencies [target]&apos;. 原来是systemctl命令要逐渐取代原来的chkconfig和services命令。在目前很多linux的新发行版本里，系统对于daemon的启动管理方法不再采用SystemV形式，而是使用了sytemd的架构来管理daemon的启动。UpStart\SystemV\systemd三种形式。Linux 操作系统的启动首先从 BIOS 开始，接下来进入 boot loader，由 bootloader 载入内核，进行内核初始化。内核初始化的最后一步就是启动 pid 为 1 的 init 进程。这个进程是系统的第一个进程。它负责产生其他所有用户进程。大多数 Linux 发行版的 init 系统是和 System V 相兼容的，被称为 sysvinit。这是人们最熟悉的 init 系统。一些发行版如 Slackware 采用的是 BSD 风格 Init 系统，这种风格使用较少。其他的发行版如 Gentoo 是自己定制的。Ubuntu 和 RHEL 采用 upstart 替代了传统的 sysvinit。而 Fedora 从版本 15 开始使用了一个被称为 systemd 的新 init 系统。如果需要服务随计算机启动时启用，在Fedora 24中，以SSH服务为例： 1systemctl enable sshd.service 这样SSH守护进程就会在开机时自动启动了。输出的执行结果为： 1Created symlink from /etc/systemd/system/multi-user.target.wants/sshd.service to /usr/lib/systemd/system/sshd.service. 查看SSH守护进程当前的状态。 1systemctl start sshd.service 在 Linux 主要应用于服务器和 PC 机的时代，SysVinit 运行非常良好，概念简单清晰。它主要依赖于 Shell 脚本，这就决定了它的最大弱点：启动太慢。在很少重新启动的 Server 上，这个缺点并不重要。而当 Linux 被应用到移动终端设备的时候，启动慢就成了一个大问题。为了更快地启动，人们开始改进 sysvinit，先后出现了 upstart 和 systemd 这两个主要的新一代 init 系统。Upstart 已经开发了 8 年多，在不少系统中已经替换 sysvinit。Systemd 出现较晚，但发展更快，大有取代 upstart 的趋势。而SystemV对应的是service、UpStart对应的是chkconfig、systemd对应的是systemctl命令。 参考来源： 浅析 Linux 初始化 init 系统，第 1 部分: sysvinit]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Fedora 24添加桌面图标]]></title>
      <url>%2F2016%2F10%2F12%2Ffedora-desktop-icon%2F</url>
      <content type="text"><![CDATA[安装好了Google Chrome和Intellij Idea之后没有桌面图标，也没有快速启动图标，每次启动都要打开终端，甚是麻烦。故将图标放在桌面能够节省不少时间，同时也更加方便。首先安装gnome-tweak-tool: 1dnf install gnome-tweak-tool -y 运行gnome-tweak-tool命令，在弹出的窗口的Desktop选项卡中打开Icons on Desktop. 桌面图标切换到Desktop目录。 1cd /home/dolphin/Desktop dolphin是当前用户名。新建Google-Chrome.desktop文件。内容为： 123456789101112#!/usr/bin/env xdg-open[Desktop Entry]Encoding=UTF-8Name=Google ChromeGenericName=Web BrowserExec='/opt/google/chrome/google-chrome'Icon=/opt/google/chrome/product_logo_256.pngTerminal=falseType=ApplicationCategories=Network;Name[en_US]=Google Chrome.desktop 如下是Intellij Idea的桌面图标配置文件: 123456789101112#!/usr/bin/env xdg-open[Desktop Entry]Encoding=UTF-8Name=Intellij IdeaGenericName=IDEExec='/opt/idea/idea-IC-162.2032.8/bin/idea.sh'Icon=/opt/idea/idea-IC-162.2032.8/bin/idea.pngTerminal=falseType=ApplicationCategories=IDE;Name[en_US]=Intellij Idea 保存之后双击打开，一定要双击打开哟，否则启动图标不会出现，会出现一个确认界面。提示需要授权启动项，选择授权即可。配置好图标后的效果如图所示。 快速启动图标要让图标在快速启动栏里出现，直接将刚才新建Google-Chrome.desktop文件复制到/usr/share/application目录下即可。 1cp Google-Chrome.desktop /usr/share/application 配置好快速启动图标后的效果如下如所示。 /usr/share/application目录是Gnome中所有用户启动的快捷方式存放的目录。局部的快捷方式存放的目录在：~/.local/share/applications。desktop文件的结构如下。 12345678[Desktop Entry]Encoding=UTF-8 //字符编码Name=vim //显示的名字MimeType=text/plain; //类型Exec=vim %f //运行的程序 %f表示一个参数Type=Application //类型Terminal=true //是否使用终端NoDisplay=true //是否显示在gnome菜单里]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Intellij Idea热部署]]></title>
      <url>%2F2016%2F10%2F10%2Fintellij-hot-deply%2F</url>
      <content type="text"><![CDATA[下午遇到一个问题，在开发时，HTML修改后浏览器刷新始终不显示修改后的效果。经过朋友的指导，原来是要选择Exploded包进行部署。如图所示。 在Intellij的官方文档上如此描述：To have the application deployed as a directory, choose Web Application: Exploded.To have the application deployed in the packed form, choose Web Application: Archive.大意是如果想以目录形式部署，选择Exploded(adj. 爆炸了的；分解的；被破除的)模式,如果想以打包模式部署，则选择Archive模式。Exploded模式带来的好处是支持热部署，这样不用在开发过程中每次修改了内容后(HTML\JSP)都重新部署，重启一次大概要1-3分钟，有此可见大大提高了开发效率。缺点是多次部署后，Tomcat可能内存溢出，此时就必须重启Tomcat。 参考资料： What does Exploded Development mean? (In Java) Configuring Web Application Deployment]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Fedora 24 OpenVPN客户端配置]]></title>
      <url>%2F2016%2F10%2F09%2Ffedora-openvpn-client%2F</url>
      <content type="text"><![CDATA[安装输入如下命令安装。 1234#Fedora 24安装命令dnf install openvpn -y#CentOS 6.8安装命令(可输入lsb_release -a命令查看版本)yum intall openvpn -y 配置生成客户端文件到OpenVPN服务端easy-rsa目录下，输入如下命令生成客户端key： 1build-key client 这里介绍在Fedora中如何设置OpenVPN客户端。将生成的客户端文件拷贝到Fedora的/etc/openvpn配置目录中即可，生成的客户端文件有： ca.crt client.crt client.key client.ovpn 在Fedora中将client.ovpn改为client.conf即可。启动OpenVPN客户端(root权限): 1openvpn client.conf 开机启动输入如下命令开启开启自动启动： 123456789101112#检查OpenVPN是否在本运行级别下设置为开机启动chkconfig --list openvpn#如果没设置启动就设置下chkconfig --level 2345 openvpn onchkconfig openvpn on#重新启动service sshd restart#看是否启动了1194端口.确认下netstat -antp |grep openvpn#看看是否放行了1194口iptables -nL#setup----&gt;防火墙设置 如果没放行就设置放行. chkconfig provides a simple command-line tool for maintaining the /etc/rc[0-6].d directory hierarchy by relieving system administrators of the task of directly manipulating the numerous symbolic links in those directories. delete from positional where vtime in ( select vtime from positional group by vtime having count()&gt;1) and id not in (select top 1 id from positional group by vtime having count()&gt;1 ); 问题解决在Fedora 24中运行openvpn client.conf后提示如下错误： 123456789101112131415Sat Oct 8 23:32:19 2016 Socket Buffers: R=[87380-&gt;87380] S=[16384-&gt;16384]Sat Oct 8 23:32:19 2016 Attempting to establish TCP connection with [AF_INET]114.24.5.55:1194 [nonblock]Sat Oct 8 23:32:20 2016 TCP connection established with [AF_INET]114.24.5.55:1194Sat Oct 8 23:32:20 2016 TCPv4_CLIENT link local: [undef]Sat Oct 8 23:32:20 2016 TCPv4_CLIENT link remote: [AF_INET]114.24.5.55:1194Sat Oct 8 23:32:20 2016 TLS: Initial packet from [AF_INET]114.24.5.55:1194, sid=efc00936 581068f2Sat Oct 8 23:32:20 2016 VERIFY OK: depth=1, C=US, ST=CA, L=SanFrancisco, O=OpenVPN, OU=changeme, CN=OpenVPN_CA, name=changeme, emailAddress=mail@host.domainSat Oct 8 23:32:20 2016 VERIFY ERROR: depth=0, error=certificate signature failure: C=US, ST=CA, L=SanFrancisco, O=OpenVPN, OU=changeme, CN=server, name=changeme, emailAddress=mail@host.domainSat Oct 8 23:32:20 2016 OpenSSL: error:14090086:SSL routines:ssl3_get_server_certificate:certificate verify failedSat Oct 8 23:32:20 2016 TLS_ERROR: BIO read tls_read_plaintext errorSat Oct 8 23:32:20 2016 TLS Error: TLS object -&gt; incoming plaintext read errorSat Oct 8 23:32:20 2016 TLS Error: TLS handshake failedSat Oct 8 23:32:20 2016 Fatal TLS error (check_tls_errors_co), restartingSat Oct 8 23:32:20 2016 SIGUSR1[soft,tls-error] received, process restartingSat Oct 8 23:32:20 2016 Restart pause, 5 second(s) 发生此错误的原因是OpenSSL包中，当前使用的OpenSSL(版本：OpenSSL 1.0.0e 6 Sep 2011)默认的摘要算法为MD5。而MD5算法在目前是非常不安全的(Hash碰撞攻击等)，较大的彩虹表可以轻易的找出Hash对应值。所以在较新的操作系统(这里是Fedora 24)已经默认不使用MD5算法，所以会有此错误(Windows 7支持MD5)。解决此问题的思路不外乎2种，一种是使用sha256、sha512等摘要算法(MD)，另一种就是启用操作系统对MD5的支持,推荐前者。 修改加密方式(推荐)修改加密方式在OpenVPN目录的文件中(我的是在C:\Program Files (x86)\OpenVPN\easy-rsa\openssl-1.0.0.cnf)。将 1default_md = md5 # use public key default MD 改为 1default_md = sha256 # use public key default MD 启用操作系统MD5支持Temporally enable it. 12export NSS_HASH_ALG_SUPPORT=+MD5export OPENSSL_ENABLE_MD5_VERIFY=1 Enable MD5 support through NetworkManager 1$ sudo vim /usr/lib/systemd/system/NetworkManager.service Append this. 12[Service]Environment=&quot;OPENSSL_ENABLE_MD5_VERIFY=1 NSS_HASH_ALG_SUPPORT=+MD5&quot; And restart daemon 12$ sudo systemctl daemon-reload$ sudo systemctl restart NetworkManager.service 提示如下错误： 12345678910111213Sun Oct 09 11:33:22 2016 OpenVPN 2.2.2 Win32-MSVC++ [SSL] [LZO2] [PKCS11] built on Dec 15 2011Sun Oct 09 11:33:22 2016 NOTE: OpenVPN 2.1 requires &apos;--script-security 2&apos; or higher to call user-defined scripts or executablesSun Oct 09 11:33:22 2016 LZO compression initializedSun Oct 09 11:33:22 2016 Control Channel MTU parms [ L:1544 D:140 EF:40 EB:0 ET:0 EL:0 ]Sun Oct 09 11:33:22 2016 Socket Buffers: R=[8192-&gt;8192] S=[8192-&gt;8192]Sun Oct 09 11:33:22 2016 Data Channel MTU parms [ L:1544 D:1450 EF:44 EB:135 ET:0 EL:0 AF:3/1 ]Sun Oct 09 11:33:22 2016 Local Options hash (VER=V4): &apos;69109d17&apos;Sun Oct 09 11:33:22 2016 Expected Remote Options hash (VER=V4): &apos;c0103fa8&apos;Sun Oct 09 11:33:22 2016 Attempting to establish TCP connection with 113.204.5.58:1194Sun Oct 09 11:33:23 2016 TCP: connect to 113.204.5.58:1194 failed, will try again in 5 seconds: Connection refused (WSAECONNREFUSED)Sun Oct 09 11:33:29 2016 TCP: connect to 113.204.5.58:1194 failed, will try again in 5 seconds: Connection refused (WSAECONNREFUSED)Sun Oct 09 11:33:35 2016 TCP: connect to 113.204.5.58:1194 failed, will try again in 5 seconds: Connection refused (WSAECONNREFUSED)Sun Oct 09 11:33:41 2016 TCP: connect to 113.204.5.58:1194 failed, will try again in 5 seconds: Connection refused (WSAECONNREFUSED) 首先检查服务端OpenVPN是否已经启动；其次检查服务端的配置文件无误，这里是将位数由1024改为2048后在服务端的配置文件没有修改为2048pem。 123456# Diffie hellman parameters.# Generate your own with:# openssl dhparam -out dh1024.pem 1024# Substitute 2048 for 1024 if you are using# 2048 bit keys.dh dh2048.pem #将此处由dh1024.pem修改为dh2048.pem即可 出现如下错误： 1234567Tue Oct 11 12:44:00 2016 Socket Buffers: R=[124928-&gt;124928] S=[124928-&gt;124928]Tue Oct 11 12:44:00 2016 UDPv4 link local: [undef]Tue Oct 11 12:44:00 2016 UDPv4 link remote: [AF_INET]192.168.24.243:1194Tue Oct 11 12:45:00 2016 TLS Error: TLS key negotiation failed to occur within 60 seconds (check your network connectivity)Tue Oct 11 12:45:00 2016 TLS Error: TLS handshake failedTue Oct 11 12:45:00 2016 SIGUSR1[soft,tls-error] received, process restartingTue Oct 11 12:45:00 2016 Restart pause, 2 second(s) 检查防火墙是否过滤了1194端口的数据。 123iptables -A INPUT -p tcp --dport 1194 -j ACCEPT#保存防火墙规则/etc/init.d/iptables save 检查配置文件是否通过TCP协议而不是UDP。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Intellij IDEA推荐插件]]></title>
      <url>%2F2016%2F10%2F08%2Fintelli-idea-plugin%2F</url>
      <content type="text"><![CDATA[presentation assistant这款插件可以实时的在Intellij屏幕底部展示当前按下的快捷键，包括Windows的快捷键和Mac的快捷键，可以帮助您记忆快捷键，清楚当前的行为(Action)。效果如下图所示。 Grep Console允许你定义一系列将通过控制台输出或文件测试的正则表达式。匹配代码行的每个表达式将会影响整行的样式，或播放声音。例如，错误消息可以被设置在一个红色的背景中显示。例如错误(ERROR)输出为红色，报警(WARNING)输出为黄色，信息(INFO)输出为绿色。 JRebel for IntelliJ(Commercial)JRebel的热部署可以让你修改代码以后不用重新启动项目即可加载效果，即所谓的热部署，可以大大提高开发效率。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[rm命令安全]]></title>
      <url>%2F2016%2F10%2F08%2Frm-command%2F</url>
      <content type="text"><![CDATA[rm命令是一个非常危险的命令，由于这个命令引发的事故不少，最近也是深深的体会到了。在此记录下如何将rm命令变为安全的命令。对于需要在Linux下开发的朋友来说，这一步(屏蔽rm危险操作)觉得是必须的，非常、非常、非常重要。怎么强调都不为过。一定要花时间做rm命令的安全工作。 建立回收站机制回收站机制-建立新命令在/usr/bin目录下建立文件erase： 12cd /usr/bintouch erase 拷贝如下Shell脚本到文件中： 1234567891011121314151617181920#! /bin/bashRecycleBin=~/.temp(($#==0)) &amp;&amp; &#123; echo "No paraments!";exit 1; &#125;if [ ! -d $RecycleBin ]; then mkdir $RecycleBinfifor i in $*do if test -e $i then cd $(dirname $i) mv -f $(basename $i) $RecycleBin/$(find $(pwd) -maxdepth 1 -name $(basename $i) | tr "/" "=") cd - else echo "$i:No such file or directory!" fidone 添加执行权限： 1chmod 777 erase 此脚本会在用户目录下新建一个隐藏的temp文件夹，将删除的文件移动到此文件夹下。命名为：=用户名=删除的文件名=。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Ambari Metrics重装]]></title>
      <url>%2F2016%2F10%2F07%2Fambari-metrics-reinstall%2F</url>
      <content type="text"><![CDATA[移除服务采用Ambari REST API移除相关服务。 123456#停止服务curl -i -H "X-Requested-By: ambari" -u admin:admin -X PUT -d '&#123;"RequestInfo":&#123;"context":"Stop Service"&#125;,"Body":&#123;"ServiceInfo":&#123;"state":"INSTALLED"&#125;&#125;&#125;' http://192.168.24.226:8080/api/v1/clusters/zwlbs/services/AMBARI_METRICS#查看服务状态curl -u admin:admin -H "X-Requested-by:ambari" -i -k -X GET http://192.168.24.226:8080/api/v1/clusters/zwlbs/services/AMBARI_METRICS/#移除服务curl -u admin:admin -H "X-Requested-By: ambari" -X DELETE http://192.168.24.226:8080/api/v1/clusters/zwlbs/services/AMBARI_METRICS cURL是一个命令行工具，通过不同的协议传输数据，1997年首次发布。cURL is a computer software project providing a library and command-line tool for transferring data using various protocols. The cURL project produces two products, libcurl and cURL. It was first released in 1997. The name originally stood for “see URL”.curl支持的协议有FTP, FTPS, HTTP, HTTPS, SCP, SFTP, TFTP, TELNET, DICT, LDAP, LDAPS, FILE, POP3, IMAP, SMTP and RTSP at the time of this writing. Wget支持HTTP, HTTPS and FTP三种协议. 移除包移除各个节点啊上安装的包。 12345678#主节点yum remove ambari-metrics-hadoop-sink-2.2.2.0-460.x86_64 -yyum remove ambari-metrics-monitor-2.2.2.0-460.x86_64 -yyum remove ambari-metrics-grafana-2.2.2.0-460.x86_64 -yyum remove ambari-metrics-collector-2.2.2.0-460.x86_64 -y#从节点yum remove ambari-metrics-monitor-2.2.2.0-460.x86_64 -yyum remove ambari-metrics-hadoop-sink-2.2.2.0-460.x86_64 -y 删除文件删除与Ambari Metrics相关的文件。 12345678910111213141516rm -rf#Ambari Metrics/usr/lib/ambari-metrics-grafana/usr/lib/ambari-metrics-hadoop-sink/usr/lib/ambari-metrics-kafka-sink/var/lib/ambari-metrics-collector/var/lib/ambari-metrics-grafana/var/run/ambari-metrics-collector/var/run/ambari-metrics-monitor/var/run/ambari-metrics-grafana/var/log/ambari-metrics-collector/var/log/ambari-metrics-monitor/var/log/ambari-metrics-grafana/etc/ambari-metrics-collector/etc/ambari-metrics-monitor/etc/ambari-metrics-grafana 可将以上代码写入Shell脚本，执行即可。 添加服务以上步骤完成后，重新到Ambari UI界面添加Ambari Metrics服务即可。如果哪个服务实在无法修复，最无奈的方法，重装此服务。 参考文章： Services and State with Ambari REST API]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[卸载HDP和Ambari]]></title>
      <url>%2F2016%2F10%2F07%2Fambari-uninstall%2F</url>
      <content type="text"><![CDATA[移除Ambari服务依次运行如下命令： 1rpm -qa | grep ambari 123456789101112ambari-server stopambari-server resetambari-agent stoprpm -qa | grep ambari#移除Ambari Server安装包yum erase ambari-server -yrm -rf /var/lib/ambari-serverrm -rf /var/run/ambari-serverrm -rf /usr/lib/amrbari-serverrm -rf /etc/ambari-serverrm -rf /var/log/ambari-serverrm -rf /usr/lib/python2.6/site-packages/ambari* Ambari Agent Cleanup Script1python /usr/lib/python2.6/site-packages/ambari_agent/HostCleanup.py -s -k users Remove Packages12yum erase -y `yum list | grep @HDP-2 | awk '&#123; print $1 &#125;'`yum erase -y `yum list | grep 2_3_ | awk '&#123; print $1&#125;'` 移除文件夹(Clean Folders)移除文件夹(Clean Folders)脚本： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889rm -rf# Log dirs/var/log/ambari-metrics-monitor/var/log/hadoop/var/log/hbase/var/log/hadoop-yarn/var/log/hadoop-mapreduce/var/log/hive/var/log/oozie/var/log/zookeeper/var/log/flume/var/log/hive-hcatalog/var/log/falcon/var/log/knox/var/lib/hive/var/lib/oozie# DataNode HDFS dirs/grid*/hadoop# Hadoop dirs/usr/hdp/usr/bin/hadoop/tmp/hadoop/var/hadoop/hadoop/*/local/opt/hadoop# Config dirs/etc/hadoop/etc/hbase/etc/oozie/etc/phoenix/etc/hive/etc/zookeeper/etc/flume/etc/hive-hcatalog/etc/tez/etc/falcon/etc/knox/etc/hive-webhcat/etc/mahout/etc/pig/etc/hadoop-httpfs# PIDs/var/run/hadoop/var/run/hbase/var/run/hadoop-yarn/var/run/hadoop-mapreduce/var/run/hive/var/run/oozie/var/run/zookeeper/var/run/flume/var/run/hive-hcatalog/var/run/falcon/var/run/webhcat/var/run/knox# ZK db files/local/home/zookeeper/*# libs/usr/lib/flume/usr/lib/storm/var/lib/hadoop-hdfs/var/lib/hadoop-yarn/var/lib/hadoop-mapreduce/var/lib/flume/var/lib/knox#Ambari Metrics/usr/lib/ambari-metrics-grafana/usr/lib/ambari-metrics-hadoop-sink/usr/lib/ambari-metrics-kafka-sink/var/lib/ambari-metrics-collector/var/lib/ambari-metrics-grafana/var/run/ambari-metrics-collector/var/run/ambari-metrics-monitor/var/run/ambari-metrics-grafana/var/log/ambari-metrics-collector/var/log/ambari-metrics-monitor/var/log/ambari-metrics-grafana/etc/ambari-metrics-collector/etc/ambari-metrics-monitor/etc/ambari-metrics-grafana# other/var/tmp/oozie Clean Repository1yum clean all 在重装之前一定要移除干净。 各个服务的目录位置如下: 1234567/etc/&lt;service_name&gt;/usr/lib/&lt;service_name&gt;/var/lib/&lt;service_name&gt;/var/log/&lt;service_name&gt;/var/run/&lt;service_name&gt;/var/tmp/&lt;service_name&gt;/tmp/&lt;service_name&gt; 参考资料来自： Uninstalling and Cleaning a HDP Node]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[dnf与yum]]></title>
      <url>%2F2016%2F10%2F05%2Fdnf-vs-yum%2F</url>
      <content type="text"><![CDATA[Fedora 24使用yum命令时标记为过期，推荐使用dnf安装。想了解一下Fedora为什么要从yum转移到dnf。大致有如下几个原因： Dependency resolution of YUM is a nightmare(包依赖解析简直是噩梦–不觉得啊) YUM don’t have a documented API(没有API文档-很稀奇吗，没文档才正常吧) No support for extensions other than Python. Lower memory reduction and less automatic synchronization of metadata – a time taking process. DNF包管理器克服了YUM包管理器的一些瓶颈，提升了包括用户体验，内存占用，依赖分析，运行速度等多方面的内容。DNF使用 RPM, libsolv 和 hawkey库进行包管理操作。DNF从Yum分支出来，使用专注于性能的C语言库hawkey进行依赖关系解析工作，大幅度提升包管理操作效率并降低内存消耗。Yum不能“Python 3 as default”，而DNF支持Python 2和Python 3。（Python 3分支自2008年发布以来积极开发了五年，已经成熟和稳定，而目前仍在维护的Python 2分支不增加新特性，只接受bug和安全修正，它最早的版本是在2000年发布的。） 参考资料来自： DNF – The Next Generation Package Management Utility for RPM Based Distributions]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Ambari与HDP离线安装]]></title>
      <url>%2F2016%2F10%2F05%2Fambari-offline-install%2F</url>
      <content type="text"><![CDATA[Ambari安装包大概有400MB，HDP所包含的所有的服务(HDFS/ZooKeeper/Kafka/Flume)大概在7GB+，采用yum安装时速度在10KB以内，简直是让人绝望的速度。所以采用离线安装，为了速度，掏出无耻的迅雷(wget下载是假的，不过可以试一试，速度不理想换迅雷)，搭建本地YUM服务。 下载包如果不知道应该下载哪个版本，可以到Repository的配置文件中查看当前版本。路径为：/etc/yum.repo.d/，查看文件ambari.repo、HDP.rep和HDP-UTILS.repo即可。 12345#下载HDP-UTILS包wget http://public-repo-1.hortonworks.com/HDP-UTILS-1.1.0.20/repos/centos7/HDP-UTILS-1.1.0.20-centos7.tar.gz#下载HDP包wget http://public-repo-1.hortonworks.com/HDP/centos7/2.x/updates/2.4.3.0/HDP-2.4.3.0-centos7-rpm.tar.gz HDP-UTILS-1.1.0.20-centos6.tar.gz包有600多MB，HDP-2.4.3.0-centos6-rpm.tar.gz包有9GB之巨。包含很多服务，瞬间理解安装的时候超时是怎么回事了。下载完毕之后将包Copy到服务器上： 12scp HDP-UTILS-1.1.0.20-centos6.tar.gzip root@192.168.24.226:/data/sourcescp ambari-2.2.2.0-centos7.tar.gz root@192.168.24.226:/data/source 解压1tar -xvf HDP-UTILS-1.1.0.20-centos6.tar.gzip -C /data/source/ 切换到目录(/data/source)下,使用Python搭建一个简单的服务器： 1python -mSimpleHTTPServer &amp; 解压之后，会有HDP，HDP-UTILS-1.1.0.20的目录生成。HDP目录：包含Hadoop的生态圈的组件，比如hdfs，hive，hbase，mahout等。HDP-UTILS-1.1.0.17目录：包含HDP平台所包含的工具组件等，比如nagios，ganglia，puppet等。 修改Repo切换到Repository配置目录下，编辑文件ambari.repo，将源地址修改为本地地址，yum将从本地地址下载安装包进行安装。 123456789#VERSION_NUMBER=2.2.2.0-460[Updates-ambari-2.2.2.0]name=ambari-2.2.2.0 - Updatesbaseurl=http://192.168.24.226:8000/AMBARI-2.2.2.0/centos7/2.2.2.0-460/gpgcheck=1gpgkey=http://192.168.24.226:8000/AMBARI-2.2.2.0/centos7/2.2.2.0-460/RPM-GPG-KEY/RPM-GPG-KEY-Jenkinsenabled=1priority=1 安装Ambari Server1234#安装Ambari Serveryum install ambari-server -y#启动Ambari Serverambari-server start 下载速度40MB/s，与6.7KB/s的速度对比，幸福感油然而生。 配置Ambari Server输入如下命令配置Ambari Server： 1ambari-server setup 数据库这里使用默认的内嵌数据库PostgreSQL。 启动Ambari12#启动Ambari Serverambari-server start 注： etc目录解释：Host-specific system-wide configuration files There has been controversy over the meaning of the name itself. In early versions of the UNIX Implementation Document from Bell labs, /etc is referred to as the etcetera(n. 等等；附加物；附加的人；以及其它) directory, as this directory historically held everything that did not belong elsewhere (however, the FHS restricts /etc to static configuration files and may not contain binaries). Since the publication of early documentation, the directory name has been re-designated in various ways. Recent interpretations include backronyms such as “Editable Text Configuration” or “Extended Tool Chest”.]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Fedora 20 安装NodeJs]]></title>
      <url>%2F2016%2F10%2F05%2Ffedora-20-install-nodejs%2F</url>
      <content type="text"><![CDATA[安装环境： Fedora 20 i386 nodejs 6.7.0 安装使用Hexo写博客需要安装NodeJs,更新系统 1yum update -y 安装GCC编译环境 1yum install g++ curl openssl openssl-devel make gcc-c++ glibc-devel -y 下载NodeJS 1234mkdir /root/temp ; cd /rootwget http://nodejs.org/dist/node-latest.tar.gztar -xvpzf node-latest.tar.gzcd node-v* 编译安装,编译安装的时间较长，需要耐心等待，编译大概在15分钟左右。 12./configuremake install 安装NPM 1curl http://npmjs.org/install.sh | sh 查看安装的NodeJs版本： 1node --version 常见问题/usr/bin/env: ‘python’: No such file or directory1dnf install python -y g++: Command not found1dnf install "gcc-c++.x86_64" -y]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[删除Apache Ambari服务]]></title>
      <url>%2F2016%2F10%2F04%2Fdelete-ambari-service%2F</url>
      <content type="text"><![CDATA[删除删除Apache Ambari服务可调用Apache Ambari REST接口： 12345#移除ZooKeeper服务curl -u admin:admin -H "X-Requested-By: ambari" -X DELETE http://192.168.24.226:8080/api/v1/clusters/zwlbs/services/ZooKeeper#移除MapReduce服务curl -u admin:admin -H "X-Requested-By: ambari" -X DELETE http://192.168.24.226:8080/api/v1/clusters/zwlbs/services/ZooKeeper/MAPREDUCE2 注意服务的名称要大写。有时删除服务时会提示如下： 1234&#123; &quot;status&quot; : 500, &quot;message&quot; : &quot;org.apache.ambari.server.controller.spi.SystemException: An internal system exception occurred: Cannot remove ZOOKEEPER. Desired state STARTED is not removable. Service must be stopped or disabled.&quot;&#125; 此时可以先改变服务状态再执行删除命令。改变服务状态命令为： 1234curl -i -H "X-Requested-By: ambari" -u admin:admin -X PUT -d '&#123;"RequestInfo":&#123;"context":"Stop Service"&#125;,"Body":&#123;"ServiceInfo":&#123;"state":"INSTALLED"&#125;&#125;&#125;' http://192.168.24.226:8080/api/v1/clusters/CLUSTER_NAME/services/SERVICE_NAME#修改ZooKeeper的状态curl -i -H "X-Requested-By: ambari" -u admin:admin -X PUT -d '&#123;"RequestInfo":&#123;"context":"Stop Service"&#125;,"Body":&#123;"ServiceInfo":&#123;"state":"INSTALLED"&#125;&#125;&#125;' http://192.168.24.226:8080/api/v1/clusters/zwlbs/services/ZOOKEEPER]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Fedora 20安装中文输入法]]></title>
      <url>%2F2016%2F10%2F03%2Ffedora-20-install-input-method%2F</url>
      <content type="text"><![CDATA[安装12yum install scim -yyum install scim-pinyin -y SCIM(Smart Common Input Method)是基于GTK引擎，为GNOME/GTK环境下非英文/ASCII字符提供的输入。SCIM is a GTK-based input method engine for inputting non-English / non-ASCII characters in a GNOME/GTK environment. There is a KDE frontend called skim.它本身自带拼音、内码等输入法，同时提供简单的程序接口，方便程序员便捷的对其进行扩充。 配置在系统配置中添加安装的输入法， 选择输入法生效。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[install-chrome-in-fedora]]></title>
      <url>%2F2016%2F10%2F02%2Finstall-chrome-in-fedora%2F</url>
      <content type="text"><![CDATA[一种方法是通过yum安装。yum（全称为 Yellow dog Updater, Modified）是一个在Fedora和RedHat以及SUSE中的Shell前端软件包管理器。基於RPM包管理，能够从指定的服务器自动下载RPM包并且安装，可以自动处理依赖性关系，并且一次安装所有依赖的软体包，无须繁琐地一次次下载、安装。yum提供了查找、安装、删除某一个、一组甚至全部软件包的命令，而且命令简洁而又好记。 创建Repo在目录/etc/yum.repos.d下新建google-chrome.repo文件。 1vi /etc/yum.repos.d/google-chrome.repo 32位操作系统写入如下代码： 123456[google-chrome]name=google-chrome - 32-bitbaseurl=http://dl.google.com/linux/chrome/rpm/stable/i386enabled=1gpgcheck=1gpgkey=https://dl-ssl.google.com/linux/linux_signing_key.pub 64位操作系统写入如下代码： 123456[google-chrome]name=google-chrome - 64-bitbaseurl=http://dl.google.com/linux/chrome/rpm/stable/x86_64enabled=1gpgcheck=1gpgkey=https://dl-ssl.google.com/linux/linux_signing_key.pub 安装1yum install google-chrome-stable 也可以直接下载rpm包进行安装。 1rpm -ivh google-chrome-stable_current_i386.rpm 提示错误如下： 1234warning: google-chrome-stable_current_i386.rpm: Header V4 DSA/SHA1 Signature, key ID 7fac5991: NOKEYerror: Failed dependencies: lsb &gt;= 4.0 is needed by google-chrome-stable-19.0.1084.56-140965.i386 libXss.so.1 is needed by google-chrome-stable-19.0.1084.56-140965.i386 安装依赖包。 1234yum install redhat-lsb -yyum install wget -yyum install libXScrnSaver -yyum install libgcrypt.so.11 12Transaction check error: file /usr/bin from install of google-chrome-stable-19.0.1084.56-140965.i386 conflicts with file from package filesystem-3.2-19.fc20.i686]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Apache-Ambari 2.2.2.0 Agent手动安装]]></title>
      <url>%2F2016%2F10%2F02%2Fapache-ambari-using%2F</url>
      <content type="text"><![CDATA[Apache-Ambari 2.2.2.0 CentOS 7.0 Ambari是一款用于部署、管理、监控Hadoop集群的开源工具，通过Ambari用户可以更方便地管理大规模Hadoop集群。Ambari架构采用的是Server/Client的模式，主要由两部分组成：ambari-agent和ambari-server。ambari依赖其它已经成熟的工具，例如其ambari-server就依赖python，而ambari-agent还同时依赖ruby, puppet，facter等工具，还有它也依赖一些监控工具nagios和ganglia用于监控集群状况。目前能找到2种，一种是Apache Ambari，一种是Hortonworks Ambari，两者区别不大，这里安装的是Apache Ambari。 下载Ambari repository。 123cd /etc/yum.repos.d/#(Redhat/CentOS/Oracle) 6:http://public-repo-1.hortonworks.com/ambari/centos6/2.x/updates/2.2.2.0/ambari.repowget &lt;ambari-repo-url&gt; 安装ambari-agent。 1yum install ambari-agent -y 启动Agent： 1ambari-agent start 查看Agent运行状态： 1ambari-agent status 至此，Ambari Agent安装完毕。Apache Agent的日志在目录/var/log/ambari-agent/下，配置文件是/etc/ambari-agent/conf/ambari-agent.ini。 清除停止Ambari Agent： 1ambari-agent status 运行HostCleanup.py脚本123python /usr/lib/python2.6/site-packages/ambari_agent/HostCleanup.py \--silent --skip=users \-o /tmp/cleanup.log 移除 Ambari RPM、目录和符号链接在每个 Ambari 节点上，运行以下命令： 1yum erase -y ambari-* 在Ambari服务器节点上，运行以下命令：Bash1rm -rf /usr/lib/ambari-server 在每个 Ambari 代理程序节点上，运行以下命令： 1rm -rf /usr/lib/python2.6/site-packages/ambari_agent 可使用以下代码移除已损坏链接：1rm -rvf /usr/lib/python2.6/site-packages/ambari* /usr/lib/python2.6/site-packages/resource-management]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Hadoop 2.7.1集群部署(不断更新...)]]></title>
      <url>%2F2016%2F10%2F01%2Fhadoop-cluster-deploy%2F</url>
      <content type="text"><![CDATA[所用软件版本： Java 1.8.0_60 Hadoop 2.7.1.2.4.3.0-227 HBase集群建立在hadoop集群基础之上，所以在搭建HBase集群之前需要把Hadoop集群搭建起来，并且要考虑二者的兼容性。 下载JDK8u60安装包，输入如下命令进行安装： 1rpm -ivh jdk-8u60-linux-x64.rpm 添加环境变量说到可以将 Hadoop 安装目录加入 PATH 变量中，这样就可以在任意目录中直接使用 hadoo、hdfs 等命令了，如果还没有配置的，需要在 Master 节点上进行配置。首先执行 vim ~/.bashrc，加入一行： 1export PATH=$PATH:/usr/hdp/2.4.3.0-227/hadoop/bin 保存后执行source ~/.bashrc使配置生效。 配置集群/分布式环境core-site.xml12 hdfs-site.xml12 mapred-site.xml12 yarn-site.xml12 启动Hadoop关闭防火墙1234#CentOS 6.x关闭防火墙服务service iptables stop#CentOS 7，需通过如下命令关闭systemctl stop firewalld.service 启动服务(严格按照顺序)启动Zookeeper服务ZooKeeper是一个分布式开源框架，提供了协调分布式应用的基本服务，它向外部应用暴露一组通用服务——分布式同步（Distributed Synchronization）、命名服务（Naming Service）、集群维护（Group Maintenance）等，简化分布式应用协调及其管理的难度，提供高性能的分布式服务。ZooKeeper本身可以以Standalone模式安装运行，不过它的长处在于通过分布式ZooKeeper集群（一个Leader，多个Follower），基于一定的策略来保证ZooKeeper集群的稳定性和可用性，从而实现分布式应用的可靠性。如下命令启动Zookeeper服务： 1./zkServer.sh start 查看服务状态： 1./zkServer.sh status 也可以用如下命令查看： 1jps | grep Quorum The jps command lists the instrumented Java HotSpot VMs on the target system. The command is limited to reporting information on JVMs for which it has the access permissions.如果服务启动失败或者遇到问题，可到相应目录查看启动日志,日志的配置在zookeeper-env.sh文件中。 1export ZOO_LOG_DIR=/var/log/zookeeper 启动Hadoop守护进程使用如下命令启动NameNode： 1./hadoop-daemon.sh start namenode 启动Hadoop启动Hadoop集群需要启动HDFS集群和Map/Reduce集群。第一次启动先初始化namenode: 12#格式化一个新的分布式文件系统hadoop namenode -format 启动HDFS命令shell脚本在hadoop的sbin目录下。 12#启动主NameNode、DataNode./start-dfs.sh 启动YARN为从根本上解决旧MapReduce框架的性能瓶颈，促进Hadoop框架的更长远发展，从0.23.0版本开始，Hadoop的MapReduce框架完全重构，发生了根本的变化。新的Hadoop MapReduce框架命名为MapReduceV2或者叫Yarn(Yet Another Resource Negotiator，另一种资源协调者)。 1./start-yarn.sh yarn会启动ResourceManager，此处需要注意的是：Namenode和ResourceManger如果不是同一台机器，不能在NameNode上启动 yarn，应该在ResouceManager所在的机器上启动yarn。 查看集群运行状态查看集群状态验证集群是否已经成功部署。输入jps命令,输出如下所示即代表相应的服务部署OK： 1234563884 Jps1776 ResourceManager1613 SecondaryNameNode1872 NodeManager1467 DataNode1377 NameNode 参考： Hadoop集群安装配置教程 Hadoop 2.7.2安装 Hadoop新MapReduce框架Yarn详解]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Hadoop集群SSH免密钥登录]]></title>
      <url>%2F2016%2F09%2F30%2Fcluster-ssh-login%2F</url>
      <content type="text"><![CDATA[免密登录原理SSH之所以能够保证安全，原因在于它采用了公钥加密。过程如下： 远程主机收到用户的登录请求，把自己的公钥发给用户； 用户使用这个公钥，将登录密码加密后，发送回来； 远程主机用自己的私钥，解密登录密码，如果密码正确，就同意用户登录。 配置SSH免密登陆首先，运行ssh localhost来产生/home/用户名/.ssh目录，然后执行下面命令。 1ssh-keygen -t rsa 生成RSA公钥和私钥。将生成的”id_rsa.pub”追加（这里切记是追加，不是覆盖）到授权的key里面去。这样的效果是实现了当前用户无密SSH登陆到自己： 12#将id_rsa.pub追加到authorized_keyscat ~/.ssh/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys 如果要实现无密登陆到其它的主机，只需将生成的”id_rsa.pub”追加到其它主机的”~/.ssh/authorized_keys”中去。这里我们使用的方法是先将本机的”~/.ssh/id_rsa.pub”拷贝到你想无密登陆的主机上，再在相应的主机上使用”cat”命令将”~/.ssh/id_rsa.pub”追加到该主机的 “~/.ssh/authorized_keys”中。 1scp id_rsa.pub root@192.168.24.136:/tmp 验证当再使用如下命令： 1scp id_rsa.pub root@192.168.24.136:/tmp 从A服务器向192.168.24.136服务器拷贝时，不再提示输入密码时，则说明A服务器到192.168.24.136服务器可以免密钥登录,说明A服务器到192.168.24.136服务器的免密钥登录配置OK。 来自： SSH无密码验证配置]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[hashcode和equals的理解]]></title>
      <url>%2F2016%2F09%2F28%2Fhashcode-and-equals%2F</url>
      <content type="text"><![CDATA[hashcode作用hashcode提供了一种更加高效的寻找方式，在Set集合中的元素是无序不可重复的，要保证不重复，一种方式是在添加新数据时，逐一比较集合中已经存在的所有元素，如果当前集合的元素增多，效率是非常低的。hashcode可以解决这个问题，当向一个集合中添加某个元素，集合会首先调用hashCode方法，这样就可以直接定位它所存储的位置，若该处没有其他元素，则直接保存。若该处已经有元素存在，就调用equals方法来匹配这两个元素是否相同，相同则不存，不同则进行其他处理，比如散列到其他位置或者以链表的形式存储到当前已经存放的元素的尾部。hashcode此时作用是快速寻找处当前元素在集合中的位置，hashCode可以将集合分成若干个区域，每个对象都可以计算出他们的hash码，可以将hash码分组，每个分组对应着某个存储区域，根据一个对象的hash码就可以确定该对象所存储区域，这样就大大减少查询匹配元素的数量，提高了查询效率。 hashCode与equals在Java中hashCode的实现总是伴随着equals，他们是紧密配合的，你要是自己设计了其中一个，就要设计另外一个。当然在多数情况下，这两个方法是不用我们考虑的，直接使用默认方法就可以帮助我们解决很多问题。但是在有些情况，我们必须要自己动手来实现它，才能确保程序更好的运作。 对于equals，我们必须遵循如下规则： 对称性：如果x.equals(y)返回是“true”，那么y.equals(x)也应该返回是“true”。 反射性：x.equals(x)必须返回是“true”。 类推性：如果x.equals(y)返回是“true”，而且y.equals(z)返回是“true”，那么z.equals(x)也应该返回是“true”。 一致性：如果x.equals(y)返回是“true”，只要x和y内容一直不变，不管你重复x.equals(y)多少次，返回都是“true”。 任何情况下，x.equals(null)，永远返回是“false”；x.equals(和x不同类型的对象)永远返回是“false”。 对于hashCode，我们应该遵循如下规则： 在一个应用程序执行期间，如果一个对象的equals方法做比较所用到的信息没有被修改的话，则对该对象调用hashCode方法多次，它必须始终如一地返回同一个整数。 如果两个对象根据equals(Object o)方法是相等的，则调用这两个对象中任一对象的hashCode方法必须产生相同的整数结果。 如果两个对象根据equals(Object o)方法是不相等的，则调用这两个对象中任一个对象的hashCode方法，不要求产生不同的整数结果。但如果能不同，则可能提高散列表的性能。 至于两者之间的关联关系，我们只需要记住如下即可： 如果x.equals(y)返回“true”，那么x和y的hashCode()必须相等。 如果x.equals(y)返回“false”，那么x和y的hashCode()有可能相等，也有可能不等。 判断对象相等的整个处理流程是： 1、判断两个对象的hashcode是否相等，若不等，则认为两个对象不等，完毕，若相等，则比较equals。 2、若两个对象的equals不等，则可以认为两个对象不等，否则认为他们相等。 参考： Java提高篇（二六）—–hashCode]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Spring step by step(二)--持久化]]></title>
      <url>%2F2016%2F09%2F27%2Fspring-mybatis-integrete%2F</url>
      <content type="text"><![CDATA[环境： Windows 7 X64 Ultimate JDK 1.8 Spring-Framework 4.2.3.RELEASE MyBatis 3.3.1 Eclipse Java EE IDE for Web Developers.Version: Neon Release (4.6.0)Build id:20160613-1800 Maven 3.3.9 MySQL 5.7 MyBatis简介MyBatis是一个可以自定义SQL、存储过程和高级映射的持久层框架。MyBatis摒除了大部分的JDBC代码、手工设置参数和结果集重获。MyBatis只使用简单的XML和注解来配置和映射基本数据类型、Map 接口和POJO(Plain Ordinary Java Object)到数据库记录。相对Hibernate和Apache OJB等“一站式”ORM(Object Relational Mapping)解决方案而言，Mybatis是一种“半自动化”的ORM实现。 引入MyBatis依赖包在Maven项目的POM.xml中定义MyBatis和Spring相关包的版本。 123456&lt;properties&gt; &lt;mybatis.version&gt;3.3.1&lt;/mybatis.version&gt; &lt;mybatis.spring.version&gt;1.2.4&lt;/mybatis.spring.version&gt; &lt;spring.version&gt;4.2.3.RELEASE&lt;/spring.version&gt; &lt;druid-version&gt;1.0.26&lt;/druid-version&gt;&lt;/properties&gt; 引入Spring依赖包在Maven项目的POM.xml中引入Spring相关的依赖包。 123456789101112131415161718192021&lt;!-- Spring --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-test&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-web&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-jdbc&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt;&lt;/dependency&gt; 引入MySQL链接包1234567891011&lt;!-- mysql --&gt;&lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.30&lt;/version&gt;&lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid&lt;/artifactId&gt; &lt;version&gt;$&#123;druid-version&#125;&lt;/version&gt;&lt;/dependency&gt; Java常用的数据库连接池有DBCP、C3P0、Proxool、JBoss，此处数据库连接采用Alibaba的Druid框架，Druid是Java语言中较好的数据库连接池。Druid能够提供强大的监控和扩展功能。更加详细信息科参考阿里巴巴开源项目Druid负责人温少访谈。 引入AOP包12345678910&lt;dependency&gt; &lt;groupId&gt;org.aspectj&lt;/groupId&gt; &lt;artifactId&gt;aspectjrt&lt;/artifactId&gt; &lt;version&gt;1.7.2&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.aspectj&lt;/groupId&gt; &lt;artifactId&gt;aspectjweaver&lt;/artifactId&gt; &lt;version&gt;1.7.2&lt;/version&gt;&lt;/dependency&gt; Spring基础配置12345678910111213141516171819202122232425262728&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:aop="http://www.springframework.org/schema/aop" xmlns:context="http://www.springframework.org/schema/context" xmlns:util="http://www.springframework.org/schema/util" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop.xsd http://www.springframework.org/schema/util http://www.springframework.org/schema/util/spring-util.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd"&gt; &lt;description&gt;spring主配置文件&lt;/description&gt; &lt;util:properties id="applicationProperties" location="classpath:application.properties" /&gt; &lt;context:property-placeholder properties-ref="applicationProperties" ignore-resource-not-found="true" /&gt; &lt;context:component-scan base-package="dolphin.service.*"&gt; &lt;/context:component-scan&gt; &lt;!--aop 注解风格支持 proxy-targer-class默认false,用jdk动态代理,true是cglib .expose-proxy当前代理是否为可暴露状态,值是"ture",则为可访问。 --&gt; &lt;aop:aspectj-autoproxy expose-proxy="true" proxy-target-class="true" /&gt; &lt;aop:config expose-proxy="true" proxy-target-class="true" /&gt; &lt;import resource="classpath:spring-config/spring-mybatis.xml" /&gt; &lt;import resource="classpath:spring-config/spring-datasource.xml" /&gt;&lt;/beans&gt; Spring 自 2.0 版本开始，陆续引入了一些注解用于简化 Spring 的开发。@Repository 注解便属于最先引入的一批，它用于将数据访问层 (DAO 层 ) 的类标识为 Spring Bean。具体只需将该注解标注在 DAO 类上即可。同时，为了让 Spring 能够扫描类路径中的类并识别出 @Repository 注解，需要在 XML 配置文件中启用 Bean 的自动扫描功能，这可以通过context:component-scan实现。context:component-scan定义了相关Bean的扫描路径。就不再需要在 XML 中显式使用 进行 Bean 的配置。Spring 在容器初始化时将自动扫描 base-package 指定的包及其子包下的所有 class 文件，所有标注了 @Repository 的类都将被注册为 Spring Bean。 新建Spring-Mybatis配置文件1234567891011121314151617181920&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:tx="http://www.springframework.org/schema/tx" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx.xsd"&gt; &lt;description&gt;Spring 整合 MyBatis&lt;/description&gt; &lt;!-- 在基本的MyBatis中，session 工厂可以使用SqlSessionFactoryBuilder.来创建。在MyBatis-Spring中，使用了SqlSessionFactoryBean来替代。 --&gt; &lt;bean id="sqlSessionFactory" class="org.mybatis.spring.SqlSessionFactoryBean"&gt; &lt;property name="dataSource" ref="dataSource" /&gt; &lt;!-- 指定sqlMapConfig总配置文件，订制的environment在spring容器中不在生效 --&gt; &lt;property name="configLocation" value="classpath:mybatis-config.xml" /&gt; &lt;/bean&gt; &lt;!-- Mybatis 映射文件路径 用逗号隔开 --&gt; &lt;bean class="org.mybatis.spring.mapper.MapperScannerConfigurer"&gt; &lt;property name="basePackage" value="dolphin.dao" /&gt; &lt;property name="sqlSessionFactoryBeanName" value="sqlSessionFactory" /&gt; &lt;/bean&gt;&lt;/beans&gt; 新建MyBatis配置文件123456789101112131415161718192021222324252627&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;!DOCTYPE configuration PUBLIC "-//mybatis.org//DTD Config 3.1//EN""http://mybatis.org/dtd/mybatis-3-config.dtd"&gt;&lt;configuration&gt; &lt;!--设置--&gt; &lt;settings&gt; &lt;!-- 全局映射器启用缓存，不建议使用mybatis自己的缓存--&gt; &lt;setting name="cacheEnabled" value="false" /&gt; &lt;!-- 查询时，关闭关联对象即时加载以提高性能 --&gt; &lt;setting name="lazyLoadingEnabled" value="true" /&gt; &lt;!-- 设置关联对象加载的形态，此处为按需加载字段(加载字段由SQL指定)，不会加载关联表的所有字段，以提高性能 --&gt; &lt;setting name="aggressiveLazyLoading" value="false" /&gt; &lt;!-- 对于未知的SQL查询，允许返回不同的结果集以达到通用的效果 --&gt; &lt;setting name="multipleResultSetsEnabled" value="true" /&gt; &lt;!-- 允许使用列标签代替列名 --&gt; &lt;setting name="useColumnLabel" value="true" /&gt; &lt;!-- 允许使用自定义的主键值(比如由程序生成的UUID 32位编码作为键值)，数据表的PK生成策略将被覆盖 --&gt; &lt;setting name="useGeneratedKeys" value="true" /&gt; &lt;!-- 给予被嵌套的resultMap以字段-属性的映射支持 --&gt; &lt;setting name="autoMappingBehavior" value="FULL" /&gt; &lt;!-- 对于批量更新操作缓存SQL以提高性能 但是返回id有问题--&gt; &lt;setting name="defaultExecutorType" value="SIMPLE" /&gt; &lt;!-- 数据库超过36000秒仍未响应则超时 --&gt; &lt;setting name="defaultStatementTimeout" value="36000" /&gt; &lt;setting name="mapUnderscoreToCamelCase" value="true"/&gt; &lt;/settings&gt;&lt;/configuration&gt; 数据库链接配置1234567#=========================================# DataSource#=========================================jdbc.driverClass = com.mysql.jdbc.Driverjdbc.url = jdbc:mysql://127.0.0.1:3306/testjdbc.username = rootjdbc.password =123456 新建POJO12345678910111213141516171819202122public class Country &#123; private Integer id; public Integer getId() &#123; return id; &#125; public void setId(Integer id) &#123; this.id = id; &#125; private String countryName; public String getCountryName() &#123; return countryName; &#125; public void setCountryName(String countryName) &#123; this.countryName = countryName; &#125;&#125; 新建DAO123public interface CountryDao &#123; Country getCountry(int id);&#125; 新建Mapper123456789101112&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;!DOCTYPE mapper PUBLIC "-//mybatis.org//DTD Mapper 3.3//EN" "http://mybatis.org/dtd/mybatis-3-mapper.dtd"&gt;&lt;mapper namespace="dolphin.dao.CountryDao"&gt; &lt;select id="getCountry" parameterType="int" resultType="dolphin.mode.Country"&gt; SELECT * FROM country WHERE id = #&#123;id&#125; &lt;/select&gt;&lt;/mapper&gt; 新建Service123public interface CountryService &#123; Country getCountyById(int id);&#125; 实现接口123456789@Servicepublic class CountryServiceImpl implements CountryService&#123; @Autowired private CountryDao countryDao; public Country getCountyById(int id) &#123; return countryDao.getCountry(id); &#125;&#125; 新建测试类1234@RunWith(SpringJUnit4ClassRunner.class)@ContextConfiguration("classpath:spring-config/spring-base.xml")public class BasicTest &#123;&#125; 12345678910111213141516public class PageMapperTest extends BasicTest &#123; @Autowired private CountryService countryService; @Test public void test() &#123; try &#123; Country country = countryService.getCountyById(1); System.out.print(country.getId()); &#125; catch (Exception e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; &#125;&#125; 新建数据库表12345678910111213141516USE `test`;## Table structure for table country#DROP TABLE IF EXISTS `country`;CREATE TABLE `country` ( `Id` int(11) NOT NULL AUTO_INCREMENT COMMENT '主键', `countryname` varchar(255) DEFAULT NULL COMMENT '名称', `countrycode` varchar(255) DEFAULT NULL COMMENT '代码', PRIMARY KEY (`Id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT='国家信息';INSERT INTO `country` VALUES (1,'Angola','AO');INSERT INTO `country` VALUES (2,'Afghanistan','AF'); 启动测试结果如下如所示。 引用文章： 详解 Spring 3.0 基于 Annotation 的依赖注入实现]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[IntelliJ Idea快捷键技巧分享]]></title>
      <url>%2F2016%2F09%2F26%2Fintllij-idea-encoding%2F</url>
      <content type="text"><![CDATA[输入乱码在控制台输入中文时显示的不是输入的汉字，而是显示正方形符号，此时输入的汉字显示乱码，如图所示。 解决此问题，可使用支持中文较好的字体，覆盖默认字体，在Intellig Idea中的File-Settings-Appearance&amp;Behavior-Appearance中(Ctrl + Alt + S)。如下图所示。 在Debug控制台中Tomcat中输出乱码，可以打开Run/Debug Configuration,选择你的tomcat。在Server &gt; VM options设置为-Dfile.encoding=UTF-8 ，重启tomcat。 智能提示敏感调整在智能提示时默认大小写敏感，比如String的智能提示就必须首字母大写才能够准确定位，经常大小写切换，不是特别方便。在settings-Editor-General-Code Completion里设置后，可以省去大小写切换操作。 Live TemplatesLive templates帮助你快速、高效、精准的输入经常使用的或者自定义的代码片段(Live templates let you insert frequently-used or custom code constructs into your source code file quickly, efficiently, and accurately).相当于一个代码块的缩写，输入Ctrl + J会显示当前上下文中所有可用的模板。快速输入foreach，在方法内(一定要在方法里敲)输入iter + TAB。 快速进行空判断输入ifn，按TAB即可。 123if (args == null) &#123;&#125; 快速输入Main方法输入psvm,按TAB键即可。 123public static void main(String[] args) &#123;&#125; Surround with用于快速添加try catch等代码块，The Surround with feature allows you easily put expressions or statements within blocks or language constructs.快捷键为：Ctrl + Alt + T。 重构(Reflactor)重命名(Rename)Shift + F6,可以重命名你的类、方法、变量等等。 主题(Theme)更换默认主题在settings(Ctrl + Alt + S) –&gt; editor –&gt; colors &amp; fonts –&gt; general，如下图所示，如果需要修改主题的字体等是默认是不允许的，需要复制一个新的主题，再自定义修改相应的参数。 Maven配置使用Maven最头疼的就是从中央库下载jar包超级慢，等待下载jar包的感觉用重庆话讲：肚肠子把把逗紧了。解决办法就是使用私服地址，私服可以使用本地配置的Maven(不是Intellij Idea里面的boundle Maven)，修改Intellj Maven采用本机安装Maven在设置(Ctrl + Alt + S)中输入Maven，修改地址(例如：D:\Source\zwnewplatform\javasoftware\runtime\apache-maven-3.3.9)即可，如下图所示。 常用快捷键Intellij Idea可以完全丢掉键盘工作，有点早期Vim和Emacs编辑器的味道。善用Intellij Idea编辑器可以大幅提高工作效率，用快捷键有一种装逼的感觉，装逼人士必备。 快捷键(Short Keys) 作用 Ctrl + Shift + F12 编辑区全屏 Ctrl + F4 关闭当前编辑文件 Alt + 1 打开项目树视图,并将光标定位到当前编辑文件在项目树上的位置 Alt + Home 定位到导航条 Ctrl + Shift + N 定位到某一个文件(定位到指定文件) Shift + Esc 隐藏底部(如：Debug、TODO等)窗口 F12 把焦点从编辑器移到最近使用的工具窗口，可用于显示底部(如：Debug、TODO等)对应窗口 Alt + 5 激活Debug窗口 Alt + 7 打开Structure窗口(Structure前面有一个带有下划线的5是快捷键提示) Ctrl + N 根据输入的类名查找类文件 Ctrl + Shift + N 查找文件 Alt + Insert 生成Getter、Setter Ctrl + F12 在当前编辑的文件中快速导航 Alt + F3(Search/Incremental Search ) 在编辑器中实现快速查查找功能 Ctrl + J 如果记不住Live Template的缩写，使用此快捷键可以弹出所有Live Template的缩写 Ctrl + X 删除行，剪切(Cut) Ctrl + Alt + F12 显示当前项目树结构文件/文件夹所在目录，可以快速打开文件夹 Ctrl + Shift + T(Test) 选中类名，按下快捷键,创建一个新的测试Case Ctrl + Shift + 数字键(NumPad)+ 展开所有 Ctrl + Shift + 数字键(NumPad)- 折叠所有 Ctrl + 数字键(NumPad)- 在项目树上应用此快捷键可以折叠所有展开的文件夹 Ctrl + F12 打开Intellij中嵌入的终端(Terminal) Ctrl + B 跳转到实现处 Ctrl + F8 设置断点和取消设置断点 Alt + Up/Down 跳转到下一个方法或者属性 Ctrl + Tab 编辑窗口切换(切换Debug视图、编辑区类文件等) Shift + F2/F2 跳到上/下一个错误处 Alt + F1 选中目标，可以定位到文件等各种对象，Alt + F1弹出的界面中选择需要定位的对象，也可以理解成对象导航 Shift + F6 重构、重命名 Ctrl + Shift + F10 运行测试，注意运行测试时界面需要切换到测试类的界面 Alt + F8 计算变量值 Alt + Left/Right 按左/右方向切换当前已打开的文件视图 Ctrl + F10 更新资源和类文件，热部署(需要配置，部署时选择Exploded模式) Ctrl + Shift + T 新建测试类，在测试类与被测试类之间跳转 Ctrl + Shift +F 全文查找，类似于Eclipse的Ctrl + H Ctrl + Shift + Alt + N 全文搜索，包含Maven引用的jar包里面的内容，在搜索界面中，需要勾选Include non-project symbols Ctrl + Alt + Left/Right 到上一次/下一次编辑的位置 Ctrl + Y 删除光标所在行或删除选中的行 Ctrl + P(Parameter) 方法参数提示显示,当调用方法时未出现参数的智能提示时，可以手动显示方法的提示 Ctrl + Q 光标所在的变量/类名/方法名等上面（也可以在提示补充的时候按），显示文档内容 Ctrl + Shift + Up/Down 代码行上下移动 Ctrl + Shift + U 变量转换为大写 Ctrl + W 选中光标所在位置的单词(Words),递进式选择代码块。可选中光标所在的单词或段落，连续按会在原有选中的基础上再扩展选中范围 Ctrl + Alt + O 优化(Optimization)类的Import 进入退出全屏使用快捷键Alt + V打开View菜单，移动上下键选择Enter Full Screen即可。也可以自定义快捷键。 properties显示中文使用IntelliJ Idea打开属性文件时，如果包含中文，显示为原始的编码，正确显示中文需要做如下设置，到设置(settings)中,可以使用快捷键Ctrl + Alt + S打开设置界面，找到File Encoding选项卡，选中Default encoding for properties file即可，如下图所示. 限制编辑器Tab页个数有时我们并不习惯在编辑器中打开太多的Tab页，如果不小心点开了7个以上的Tab页，在Tab页面中切换也蛮让人晕眩的，设置Tab页最大个数在Settings(Ctrl + Alt + S),Editor-General-Editor Tabs中，如下图如所示。 注释模板参考： Java开发必装的IntelliJ IDEA插件 Surrounding Blocks of Code with Language Constructs]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Spring step by step(一)--依赖注入(Dependency Injection)]]></title>
      <url>%2F2016%2F09%2F25%2Fspring-ioc%2F</url>
      <content type="text"><![CDATA[为什么要依赖注入依赖注入(Dependency Injection)所要达到的目标是实现程序间的松耦合。将服务的调用者和服务的提供者分离。DI提供一种机制，在运行时绑定服务的提供者和调用者。 新建项目新建一个Web项目，目录结构如下。 引入包引入servlet-api.jar包，目录结构如下。 注意引入servlet-api.jar包后，多了src/main/java目录和src/test/java目录。servlet-api.jar包中，实现了Sevlet规范，在Apache Tomcat 8.0.37中实现的是Servlet Specification 3.1，JSP Specification 2.3。版本之间详细的对应关系可以看Apache Tomcat Versions。 添加Spring依赖包在Maven的POM文件中添加spring-context依赖。 12345&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context&lt;/artifactId&gt; &lt;version&gt;4.3.3.RELEASE&lt;/version&gt;&lt;/dependency&gt; 此处虽然只添加了一个jar包，Maven会自动下载此jar包相关的依赖包。在Maven的Dependency Hierarchy中查看包与包之间的依赖关系如下图所示。 添加类123public interface MessageService &#123; String getMessage();&#125; 1234567891011121314@Componentpublic class MessagePrinter &#123; final private MessageService service; @Autowired public MessagePrinter(MessageService service) &#123; this.service = service; &#125; public void printMessage() &#123; System.out.println(this.service.getMessage()); &#125;&#125; 带有 @Configuration 的注解类表示这个类可以使用 Spring IoC 容器作为 bean 定义的来源。@Bean 注解告诉 Spring，一个带有 @Bean 的注解方法将返回一个对象，该对象应该被注册为在 Spring 应用程序上下文中的 bean。 123456789101112131415161718@Configuration@ComponentScanpublic class Application &#123; @Bean MessageService mockMessageService() &#123; return new MessageService() &#123; public String getMessage() &#123; return "Hello World!"; &#125; &#125;; &#125; public static void main(String[] args) &#123; ApplicationContext context = new AnnotationConfigApplicationContext(Application.class); MessagePrinter printer = context.getBean(MessagePrinter.class); printer.printMessage(); &#125;&#125; 上面的代码(排除Main函数)等同于: 123&lt;beans&gt; &lt;bean id="mockMessageService" class="dolphin.MessageService" /&gt;&lt;/beans&gt; 带有 @Bean 注解的方法名称作为 bean 的 ID，它创建并返回实际的 bean。配置类可以声明多个 @Bean。一旦定义了配置类，你就可以使用 AnnotationConfigApplicationContext 来加载并把他们提供给 Spring 容器(Main方法中即是)。 运行结果如图所示。 来自： spring-framework-quick-start]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Eclipse断点类型]]></title>
      <url>%2F2016%2F09%2F24%2Feclipse-breakpoint-type%2F</url>
      <content type="text"><![CDATA[本文的Eclipse版本为:Eclipse Java EE IDE for Web Developers. Version: Neon Release (4.6.0)Build id: 20160613-1800 Line BreakpointLine Breakpoint是最简单的Eclipse断点，只要双击某行代码对应的左侧栏，就对该行设置上断点。断点的颜色为一个蓝色的实心点。 Watchpoint关注某个关键变量的变化或使用。此时，就可以为该变量设置一种特殊的断点–Watchpoint。 Method Breakpoint关注程序对某个方法的调用情况，即，可以设置Method Breakpoint。 断点上的左右小箭头代表进入和退出方法时命中。 Exception Breakpoint某个特定异常发生时程序能够被中断，以方便查看当时程序所处的状态。 Class Load Breakpoint当某个类被加载时，通过该断点可以中断程序。 来自： 详解Eclipse断点]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Phoenix常用操作]]></title>
      <url>%2F2016%2F09%2F23%2Fphoenix-tutorial%2F</url>
      <content type="text"><![CDATA[简介Phoenix本意是凤凰的意思，Apache Phoenix是构建在HBase之上的关系型数据库层，作为内嵌的客户端JDBC驱动用以对HBase中的数据进行低延迟访问。Apache Phoenix会将用户编写的sql查询编译为一系列的scan操作，最终产生通用的JDBC结果集返回给客户端。数据表的元数据存储在HBase的表中被会标记版本号，所以进行查询的时候会自动选择正确的schema。直接使用HBase的API，结合协处理器（coprocessor）和自定义的过滤器的话，小范围的查询在毫秒级响应，千万数据的话响应速度为秒级。 特性Phoenix可以用SQL语句来查询Hbase，且只能查Hbase，别的类型比如查询文本文件等都不支持！如果要查文本文件等，可以使用Hive和Impala，Phoenix在Hbase上查询的性能较Hive和Impala具有优势。 常用操作登录。 1./sqlline.py localhost 查看HBase所有表。 1!tables table schema为system的是系统表。 查看HBase中表名为test的所有列。 1!columns test 表名不用加引号。 查询表数据。 123select * from test;select name from test;//查询指定列select * from test where name = 'jiangxiaoqiang';//条件查询 删除表数据。 12delete from test where condition;//语法delete from test where name is null;//例子 condition是过滤条件，注意结尾需要有分号，表示SQL语句已经结束，可以提交给引擎执行。 清除表的重复数据。 1delete from tablename where vtime in ( select vtime from tablename group by vtime having count(*)&gt;1) and id not in (select max(id) from tablename group by vtime having count(*)&gt;1 ); 清除同一时间重复的数据（同一时刻只能有1条数据）。 连接查询。 1SELECT P.id as id, vtime, A.description FROM 表P P left join 表A A on P.id=A.positional_Id WHERE P.vehicle_id='cae21196-cb66-4256-88a6-7cdfb23e2c78' and P.vtime &gt;= '2016-10-10 00:00:00' and P.vtime &lt;= '2016-10-13 23:59:59' and P.alarm is not null and P.alarm != '0' order by P.vtime; 注意在做MyBatis映射时，P.id列需要一个别名，对应定义的实体字段。 函数(Function)substr函数用于截取字符串。 1select substr(time,0,11) from test group by substr(time,0,11); time为需要截取的字符串，从第0位开始截取11位长度。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Tomcat 8.0 HTTP请求流程]]></title>
      <url>%2F2016%2F09%2F22%2Ftomcat-http%2F</url>
      <content type="text"><![CDATA[假设来自浏览器的请求为：http://localhost:8080/test/index.jsp Connector获取请求请求被发送到Apache Tomcat服务器端口8080，被在那里侦听的Coyote HTTP/1.1 Connector(org.apache.tomcat.util.net.NioEndpoint)获得。Tomcat源码中与connector相关的类位于org.apache.coyote包中，Connector分为以下几类： Http Connector 基于HTTP协议，负责建立HTTP连接。它又分为BIO Http Connector与NIO Http Connector(org.apache.tomcat.util.net.NioEndpoint)两种。BIO(blocking I/O)，顾名思义，即阻塞式I/O操作，表示Tomcat使用的是传统的Java I/O操作(即java.io包 及其子包)。一般而言，bio模式是三种运行模式中性能最低的一种。NIO为Network IO，后者提供非阻塞IO与长连接Comet支持。NIO(new I/O)，是Java SE 1.4及后续版本提供的一种新的I/O操作方式(即java.nio包及其子包)。Java nio是一个基于缓冲区、并能提供非阻塞I/O操作的Java API，因此nio也被看成是non-blocking I/O的缩写。它拥有比传统I/O操作(bio)更好的并发运行性能。 AJP Connector 基于AJP协议，AJP是专门设计用来为tomcat与http服务器之间通信专门定制的协议，能提供较高的通信速度和效率。如与Apache服务器集成时，采用这个协议。AJP(Apache JServ Protocol)协议：目前正在使用的AJP协议的版本是通过JK和JK2连接器提供支持的AJP13，它基于二进制的格式在Web服务器和Tomcat之间传输数据，而此前的版本AJP10和AJP11则使用文本格式传输数据。 APR HTTP Connector org.apache.tomcat.util.net.AprEndpoint，用C实现，通过JNI(Java Native Interface)调用的。主要提升对静态资源(如HTML、图片、CSS、JS等)的访问性能。现在这个库已独立出来可用在任何项目中。Tomcat在配置APR之后性能非常强劲。APR(Apache Portable Runtime/Apache可移植运行时)，是Apache HTTP服务器的支持库。你可以简单地理解为，Tomcat将以JNI的形式调用Apache HTTP服务器的核心动态链接库来处理文件读取或网络传输操作，从而大大地提高Tomcat对静态文件的处理性能。Tomcat apr也是在Tomcat上运行高并发应用的首选模式。与配置nio运行模式一样，也需要将对应的Connector节点的protocol属性值改为org.apache.coyote.http11.Http11AprProtocol。 Tomcat7和Tomcat8默认设置都是http1.1，Tomcat7默认使用BIO，Tomcat8根据情况自动选择BIO还是NIO，甚至NIO2.当前调试版本是Tomcat 8，默认进入的是NioEndpoint(其实这里已经到AbstractEndpoint的Processor了，在NioEndpoint的断点始终没有命中，不知何故)，如下图所示。 Engine处理请求Connector把该请求交给它所在的Service的Engine(StandardEngine)来处理，并等待Engine的回应。Container 是容器的父接口，所有子容器都必须实现这个接口，Container 容器的设计用的是典型的责任链的设计模式，它有四个子容器组件构成，分别是：Engine、Host、Context、Wrapper，这四个组件不是平行的，而是父子关系，Engine 包含 Host,Host 包含 Context，Context 包含 Wrapper。通常一个 Servlet class 对应一个 Wrapper，如果有多个 Servlet 就可以定义多个 Wrapper，如果有多个 Wrapper 就要定义一个更高的Container。详细的关系在server.xml可以看出来： 1234567891011&lt;Server&gt;&lt;!--顶层元素，代表一个服务器--&gt; &lt;Service&gt;&lt;!--顶层元素，是Connector的集合，只有一个Engine--&gt; &lt;Connectior/&gt;&lt;!--连接器类元素，代表通信接口--&gt; &lt;Engine&gt;&lt;!--容器类元素，为特定的Service组件处理所有客户请求，可包含多个Host--&gt; &lt;Host&gt;&lt;!--为特定的虚拟主机处理所有客户请求--&gt; &lt;Context&gt;&lt;!--为特定的WEB应用处理所有客户请求--&gt; &lt;/Context&gt; &lt;/Host&gt; &lt;/Engine&gt; &lt;/Service&gt;&lt;/Server&gt; 匹配HostEngine获得请求localhost:8080/test/index.jsp，匹配它所有虚拟主机HostEngine匹配到名为localhost的Host（即使匹配不到也把请求交给该Host处理，因为该Host被定义为该Engine的默认主机） 匹配Contextlocalhost Host获得请求/test/index.jsp，匹配它所拥有的所有ContextHost匹配到路径为/test的Context（如果匹配不到就把该请求交给路径名为””的Context去处理） 匹配Servletpath=”/test”的Context获得请求/index.jsp，在它的mapping table中寻找对应的servletContext匹配到URL PATTERN为*.jsp的servlet，对应于JspServlet类构造HttpServletRequest对象和HttpServletResponse对象，作为参数调用JspServlet的doGet或doPost方法 返回响应Context把执行完了之后的HttpServletResponse对象返回给HostHost把HttpServletResponse对象返回给EngineEngine把HttpServletResponse对象返回给ConnectorConnector把HttpServletResponse对象返回给客户browser 请求流程图(Graphiz绘制)：]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[在Eclipse中启动和调试Tomcat（二）]]></title>
      <url>%2F2016%2F09%2F20%2Flaunching-and-debugging-tomcat-extra%2F</url>
      <content type="text"><![CDATA[在Eclipse中启动和调试Tomcat（一）中，断点只能在自定义Servlet中命中，如果想观察详细的Tomcat运行过程，还需要从Tomcat的入口开始进行调试。详细步骤如下(未完全通过，暂勿参考)： 引入Tomcat8.0.37jar包由于Tomcat的入口类JIoEndPoint实现在tomcat-coyote.jar包中，入口org.apache.tomcat.util.net.JIoEndpoint，该类用来处理传递进来的TCP连接，它实现了一个简单的服务器模式：一个监听线程用来接收socket以及为每个进来的连接创建一个worker来处理。更加高级的功能会涉及到线程重用，如队列等。所以需要引入Tomcat8.0.37中的tomcat-coyote.jar包，在Tomcat8项目的lib目录中。 附加源码附加源码如下图所示。 调试在JIoEndPoint类中的processSocket方法上新建断点，在浏览器中请求地址即可命中断点，单步跟踪调试即可。Tomcat中支持两种协议的连接器：HTTP/1.1与AJP/1.3。HTTP/1.1协议负责建立HTTP连接，web应用通过浏览器访问tomcat服务器用的就是这个连接器，默认监听的是8080端口；AJP/1.3协议负责和其他HTTP服务器建立连接，监听的是8009端口，比如tomcat和apache或者iis集成时需要用到这个连接器。协议上有三种不同的实现方式：JIO、APR、NIO。 JIO(java.io)：用java.io纯JAVA编写的TCP模块，这是tomcat默认连接器实现方法； APR(Apache Portable Runtime)：有C语言和JAVA两种语言实现，连接Apache httpd Web服务器的类库是在C中实现的，同时用APR进行网络通信； NIO(java.nio)：这是用纯Java编写的连接器(Conector)的一种可选方法。该实现用java.nio核心Java网络类以提供非阻塞的TCP包特性。ProtocolHandler接口是对这些协议的抽象]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[在Eclipse中启动和调试Tomcat（一）]]></title>
      <url>%2F2016%2F09%2F20%2Flaunching-and-debugging-tomcat%2F</url>
      <content type="text"><![CDATA[在Eclipse中调试Tomcat可以分析HTTP请求从Tomcat捕获到Servlet的过程。这个是调试Tomcat的目的。调试的环境是： IDE：Eclipse Java EE IDE for Web Developers.Version: Neon Release (4.6.0) Build id: 20160613-1800 Tomcat 8.0（8.0.37） JDK 1.8 OS：Windows 7 Ultimate x64 创建项目Tomcat8创建一个新的Java类型项目，项目名称为“Tomcat8”，如下如所示。 下载Tomcat 8.0.37二进制包下载Tomcat 8.0.37对应的二进制文件。将之拷贝到项目Tomcat8项目的根目录。拷贝之后Tomcat项目的目录结构如下图所示。 创建另一个项目test创建一个Maven的webapp项目,名字为“test”。 新建自定义Servlet在test项目下新建一个自定义Servlet,名字为“TestServlet”，如图所示： 由于TestServlet实现HttpServlet接口，HttpServlet接口的定义在servlet-api.jar包中，所以在test项目的Library中需要引用Tomcat8项目目录下的servlet-api.jar包。新建自定义Servlet完成后在Tomcat8项目中配置servlet映射(/webapps/examples/WEB-INF)： 1234&lt;servlet-mapping&gt; &lt;servlet-name&gt;test&lt;/servlet-name&gt; &lt;url-pattern&gt;/demo/test&lt;/url-pattern&gt;&lt;/servlet-mapping&gt; 以上映射说明从/demo/test发送的请求由名为test的Servlet来处理。在Tomcat8项目中配置servlet(/webapps/examples/WEB-INF)： 1234&lt;servlet&gt; &lt;servlet-name&gt;test&lt;/servlet-name&gt; &lt;servlet-class&gt;demo.TestServlet&lt;/servlet-class&gt;&lt;/servlet&gt; 以上配置指明名为test的Servlet处理的类的完整路径为：demo.TestServlet。 配置调试参数配置test项目，创建调试配置，配置Main Class为Tomcat的启动类： 1org.apache.catalina.startup.Bootstrap 配置test项目的工作空间为Tomcat8的工作空间，如图所示： 调试在自定义的Servlet的doGet方法上打断点，打开浏览器访问链接即可命中自定义Servlet。从这里可以加深理解HTTP请求到自定义Servlet处理的过程，可以理解Spring MVC和Tomcat是如何联系起来的。 源自： Launching and Debugging Tomcat from Eclipse without complex plugins]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Java中String非空判断]]></title>
      <url>%2F2016%2F09%2F19%2Fjava-string-not-null%2F</url>
      <content type="text"><![CDATA[如果使用的Java运行时版本在Java SE 1.6之前，可以这样判断字符串非空： 1if(str != null &amp;&amp; str.length() != 0) 如果使用的Java运行时版本是Java SE 1.6及之后版本，可以这样判断字符串非空： 1if(str != null &amp;&amp; !str.isEmpty()) 使用org.apache.commons.lang.StringUtilsApache commons-lang来完成： 12345import org.apache.commons.lang.StringUtils;if (StringUtils.isNotBlank(str)) &#123;&#125; 如下方式也可： 12345import com.google.common.base.Strings;if (!Strings.isNullOrEmpty(myString)) &#123; return myString;&#125; 源自： Java, check whether a string is not null and not empty?]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Spring MVC源码调试]]></title>
      <url>%2F2016%2F09%2F17%2Fspringmvc-sourcecode-debugging%2F</url>
      <content type="text"><![CDATA[这里调试Spring MVC的环境是： Windows 7 Eclipse Java EE IDE for Web Developers,Version: Neon Release (4.6.0).Build id: 20160613-1800 JDK 1.8 Spring MVC 4.2.3 Apache Tomcat 8.0 想了解平时学习的理论知识在实际的代码实现中是什么情况，比较好的方式是阅读源码，如果能在阅读过程中根据疑问动手调试源码验证猜想和疑问，那就更加完美了。这里想看Spring MVC一个HTTP请求从开始到结束到底是怎么运行的，Spring MVC怎么处理，选取了4.2.3版本的源码进行调试。 首先从GitHub上下载4.2.3版本的源码，在项目的Maven Dependencies找到名为spring-webmvc-4.2.3.REALEASE的jar包，单击右键build-path–&gt;Configure build path,在Libraries中找到对应的jar包，选中source attachment–&gt;Edit. 在spring-webmvc-4.2.3.REALEASE.jar中找到dispatchservlet类，打断点即可进入调试。]]></content>
    </entry>

    
  
  
</search>
